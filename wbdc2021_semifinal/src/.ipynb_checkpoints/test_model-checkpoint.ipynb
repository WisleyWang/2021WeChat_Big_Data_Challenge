{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9957d1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:10:12.241668Z",
     "start_time": "2021-06-30T11:10:01.793966Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "# import dgl.function as fn\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import auc,roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# from deepctr_torch.models.deepfm import FM,DNN\n",
    "# from deepctr_torch.layers  import CIN,InteractingLayer,CrossNet,CrossNetMix\n",
    "# from deepctr_torch.models.basemodel import *\n",
    "from collections import defaultdict\n",
    "from torch.optim import Optimizer\n",
    "# import torchtext\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24f55ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79d9581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:44:35.117914Z",
     "start_time": "2021-06-30T04:44:35.114240Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82fcc675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:44:51.233911Z",
     "start_time": "2021-06-30T04:44:35.120436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n",
      "17655.76 Mb, 17237.04 Mb (2.37 %)\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH='./wbdc2021-semi/data/'\n",
    "ratings=pd.read_pickle(ROOT_PATH+'tmp/ratings_feat_df.pkl')\n",
    "ratings=reduce_mem(ratings)\n",
    "feed_emb=np.load(ROOT_PATH+'tmp/feed_emb.npy')\n",
    "item_texts=pickle.load(open(ROOT_PATH+'tmp/item_texts.pkl','rb'))\n",
    "feed_data=pickle.load(open(ROOT_PATH+'tmp/feed_data.pkl','rb'))\n",
    "user_data=pickle.load(open(ROOT_PATH+'tmp/user_data.pkl','rb'))\n",
    "graph_emb=np.concatenate([np.load(ROOT_PATH+'tmp/grap_allembedding32_sg2.npy'),np.load(ROOT_PATH+'tmp/grap_allembedding32_hs2.npy')],axis=1)\n",
    "# feed_info=pd.read_pickle(ROOT_PATH+'tmp/cat_feed_info.pkl')\n",
    "userid2nid=pickle.load(open(ROOT_PATH+'tmp/userid2nid.pkl','rb'))\n",
    "feedid2nid=pickle.load(open(ROOT_PATH+'tmp/feedid2nid.pkl','rb'))\n",
    "feat=pickle.load(open(ROOT_PATH+'tmp/feat_list.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e16d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:44:51.245729Z",
     "start_time": "2021-06-30T04:44:51.238804Z"
    }
   },
   "outputs": [],
   "source": [
    "ACTION_LIST = [\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']#\n",
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08e5e54b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T05:00:01.866662Z",
     "start_time": "2021-06-30T04:59:41.497252Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "class BagOfWordsPretrained(nn.Module):\n",
    "    def __init__(self, field, hidden_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        input_dims = field.vocab.vectors.shape[1]\n",
    "        self.emb = nn.Embedding(\n",
    "            len(field.vocab.itos), input_dims,\n",
    "            padding_idx=field.vocab.stoi[field.pad_token])\n",
    "        self.emb.weight[:] = field.vocab.vectors\n",
    "        self.proj = nn.Linear(input_dims, hidden_dims)\n",
    "        nn.init.xavier_uniform_(self.proj.weight)\n",
    "        nn.init.constant_(self.proj.bias, 0)\n",
    "\n",
    "        disable_grad(self.emb) # 词向量不可训练\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, max_length) LongTensor\n",
    "        length: (batch_size,) LongTensor\n",
    "        \"\"\"\n",
    "        x = self.emb(x).sum(1)# / length.unsqueeze(1).float() # 归一化\n",
    "        return self.proj(x)\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, field, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.att_emb=Attn(hidden_dims)\n",
    "        self.emb = nn.Embedding(\n",
    "            len(field.vocab.itos), hidden_dims,\n",
    "            padding_idx=field.vocab.stoi[field.pad_token])\n",
    "        nn.init.xavier_uniform_(self.emb.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.att_emb(self.emb(x))#.mean(1)#/ length.unsqueeze(1).float() # 归一化\n",
    "class text_emb(nn.Module):\n",
    "    def __init__(self,weight):\n",
    "        super().__init__()\n",
    "        self.att_emb=Attn(weight.shape[1])\n",
    "        self.emb = nn.Embedding(\n",
    "            weight.shape[0],weight.shape[1],\n",
    "            padding_idx=0)\n",
    "#         nn.init.xavier_uniform_(self.emb.weight)\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(weight).float())\n",
    "#         self.emb.requires_grad_=False\n",
    "    def forward(self, x):\n",
    "        return self.att_emb(self.emb(x))#.mean(1)#/ length.unsqueeze(1).float() # 归一化\n",
    "tokenize = lambda x: x.split(' ')\n",
    "fields = {}\n",
    "examples = []\n",
    "for key, texts in item_texts.items():\n",
    "    if  key in ['ocr','asr','description']:\n",
    "        fields[key] = torchtext.data.Field(include_lengths=True, lower=True,tokenize=tokenize, batch_first=True, fix_length=64)\n",
    "    else:\n",
    "        fields[key] = torchtext.data.Field(include_lengths=True, lower=True,tokenize=tokenize, batch_first=True, fix_length=5)\n",
    "    \n",
    "for i in range(len(item_texts['ocr'])):\n",
    "    example = torchtext.data.Example.fromlist(\n",
    "        [item_texts[key][i] for key in item_texts.keys()],\n",
    "        [(key, fields[key]) for key in item_texts.keys()])  #( [feat1,feat2], [(key1,field1),(key2,field2)] )\n",
    "    examples.append(example)\n",
    "textset = torchtext.data.Dataset(examples, fields)\n",
    "for key, field in fields.items():\n",
    "    field.build_vocab(getattr(textset, key))\n",
    "    \n",
    "for field_name, field in textset.fields.items():\n",
    "    examples = [getattr(textset[i], field_name) for i in range(len(textset.examples))]\n",
    "    tokens, lengths = field.process(examples)\n",
    "    if not field.batch_first:\n",
    "        tokens = tokens.t()\n",
    "    # 给feed +上文本向量\n",
    "    feed_data[field_name] = tokens\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7cd6a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T05:00:15.547371Z",
     "start_time": "2021-06-30T05:00:15.482531Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,usr_data,feed_data,feed_embed,graph_emb):\n",
    "        super().__init__()\n",
    "        self.feed_data=feed_data\n",
    "        self.user_data=user_data\n",
    "        user_dict={'device':2,'userid':128}\n",
    "        feed_dict={'bgm_song_id':16, 'bgm_singer_id':16,'authorid':16,'dense':32,'hash_dense':32\n",
    "       ,'manual_keyword_id1':16,'manual_tag_id1':16,'machine_keyword_id1':16\n",
    "            ,'machine_tag_id1':16,'knn_feed':16,\n",
    "           'manual_tag_list':32,'manual_keyword_list':32,'machine_keyword_list':32,'asr':32,'description':32,'ocr':32\n",
    "                  }\n",
    "        self.model_dict=_init_input_modules(user_data,feed_data, user_dict,feed_dict)\n",
    "        self.spare_liner=nn.Linear(8*16,128)\n",
    "        self.dense_liner=nn.Linear(32*2,128)\n",
    "        self.text_liner=nn.Linear(32*6+512+64,128)\n",
    "        self.feed_embed= nn.Parameter(torch.from_numpy(feed_embed).float(),requires_grad=False)\n",
    "        self.graph= nn.Parameter(torch.from_numpy(graph_emb).float(),requires_grad=False)\n",
    "        self.reg_liner=nn.Linear(128,1)\n",
    "        self.dynami_dense=nn.Linear(92,64)\n",
    "        self.cross1=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "        self.cross2=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "        self.cross3=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "        self.cross4=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "        self.cross5=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "        self.cross6=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "        self.cross7=CrossNetMix(sum(user_dict.values())+128*3+64,layer_num=4)\n",
    "#         self.dnn=DNN(sum(user_dict.values())+128*3+64,(128,128),dropout_rate=0.1)\n",
    "        self.mmoe=pleLayer(sum(user_dict.values())+128*3+64, mmoe_hidden_dim=128,num_task=6,n_expert=6,n_iid_expert=4,expert_activation=None)\n",
    "#         self.att1=Attn(sum(user_dict.values())+128*3+64)\n",
    "#         self.att2=Attn(sum(user_dict.values())+128*3+64)\n",
    "#         self.att3=Attn(sum(user_dict.values())+128*3+64)\n",
    "#         self.att4=Attn(sum(user_dict.values())+128*3+64)\n",
    "        self.ln_user=nn.LayerNorm(sum(user_dict.values()))\n",
    "        self.ln_feed=nn.LayerNorm(128*3)\n",
    "        self.ln_dense=nn.LayerNorm(64)\n",
    "        \n",
    "        self.liner1=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "        self.liner2=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "        self.liner3=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "        self.liner4=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "        self.liner5=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "        self.liner6=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "        self.liner7=nn.Linear(128+sum(user_dict.values())+128*3+64,1)\n",
    "    def forward(self,userid,feedid,batch_dense,is_train=True):\n",
    "        user_projections=[]\n",
    "#         feed_projections=[]\n",
    "        dense_embedding=[]\n",
    "        sparse_embedding=[]\n",
    "        text_embedding=[]\n",
    "        for feature, data in self.user_data.items():\n",
    "            module = self.model_dict[feature]\n",
    "            result = module(data)\n",
    "            user_projections.append(result)\n",
    "        for feature, data in self.feed_data.items():\n",
    "#             print(feature)\n",
    "            module = self.model_dict[feature]\n",
    "            result = module(data)\n",
    "            if result.shape[-1]==16:\n",
    "                sparse_embedding.append(result)\n",
    "            elif 'dense' in feature:\n",
    "                dense_embedding.append(result)\n",
    "            else:\n",
    "#                 print(result.shape)\n",
    "                text_embedding.append(result)\n",
    "#         print(user_projections)\n",
    "\n",
    "        user_feat=torch.cat(user_projections,-1)\n",
    "        user_feat=self.ln_user(user_feat)\n",
    "        spare_emb=self.spare_liner(torch.cat(sparse_embedding,-1))\n",
    "        dense_emb=self.dense_liner(torch.cat(dense_embedding,-1))\n",
    "        text_emb=self.text_liner(torch.cat(text_embedding+[self.feed_embed,self.graph],-1))  \n",
    "        feed_feat=torch.cat([spare_emb,dense_emb,text_emb],-1) #128*3\n",
    "        feed_feat=self.ln_feed(feed_feat)\n",
    "        dynami_dense=self.dynami_dense(batch_dense)\n",
    "        dynami_dense=self.ln_dense(dynami_dense)\n",
    "        combine=torch.cat([user_feat[userid],feed_feat[feedid],dynami_dense],axis=-1)\n",
    "        cross1=self.cross1(combine)\n",
    "        cross2=self.cross2(combine)\n",
    "        cross3=self.cross3(combine)\n",
    "        cross4=self.cross4(combine)\n",
    "        cross5=self.cross5(combine)\n",
    "        cross6=self.cross6(combine)\n",
    "        cross7=self.cross7(combine)\n",
    "        outs=self.mmoe(combine)\n",
    "\n",
    "        \n",
    "        logit_gnn1=self.liner1(torch.cat([outs[0],cross1],axis=-1))#+ffm1#128+1+128*2\n",
    "        logit_gnn2=self.liner2(torch.cat([outs[1],cross2],axis=-1))#+ffm2\n",
    "        \n",
    "        logit_gnn3=self.liner3(torch.cat([outs[2],cross3],axis=-1))#+ffm3\n",
    "        logit_gnn4=self.liner4(torch.cat([outs[3],cross4],axis=-1))#+ffm4\n",
    "        logit_gnn5=self.liner3(torch.cat([outs[0],cross5],axis=-1))#+ffm3\n",
    "        logit_gnn6=self.liner4(torch.cat([outs[2],cross6],axis=-1))#+ffm4\n",
    "        logit_gnn7=self.liner4(torch.cat([outs[4],cross7],axis=-1))#+ffm4\n",
    "        logit_reg=self.reg_liner(outs[5])\n",
    "        return logit_gnn1,logit_gnn2,logit_gnn3,logit_gnn4,logit_gnn5,logit_gnn6,logit_gnn7,logit_reg\n",
    "    \n",
    "def _init_input_modules(user_data,feed_data, user_dict,feed_dict):\n",
    "    # We initialize the linear projections of each input feature ``x`` as\n",
    "    # follows:\n",
    "    # * If ``x`` is a scalar integral feature, we assume that ``x`` is a categorical\n",
    "    #   feature, and assume the range of ``x`` is 0..max(x).\n",
    "    # * If ``x`` is a float one-dimensional feature, we assume that ``x`` is a\n",
    "    #   numeric vector.\n",
    "    # * If ``x`` is a field of a textset, we process it as bag of words.\n",
    "    module_dict = nn.ModuleDict()\n",
    "    for column, data in user_data.items():\n",
    "        if data.dtype == torch.float32: # 数值类型的特征\n",
    "            assert data.ndim == 2\n",
    "            m = nn.Linear(data.shape[1],user_dict[column]) # 数值特征 做个线性变换\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif data.dtype == torch.int64:\n",
    "            assert data.ndim == 1  # 整形的单值特征做个embedding\n",
    "            m = nn.Embedding(data.max() + 2, user_dict[column], padding_idx=-1)\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        module_dict[column] = m  # 不同的特征名字对应不同的处理moderl 这里或许可以加FM进去\n",
    "    \n",
    "    for column, data in feed_data.items():\n",
    "        if column in item_texts.keys():\n",
    "            continue\n",
    "        if data.dtype == torch.float32: # 数值类型的特征\n",
    "            assert data.ndim == 2\n",
    "            m = nn.Linear(data.shape[1],feed_dict[column]) # 数值特征 做个线性变换\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif data.dtype == torch.int64:\n",
    "            assert data.ndim == 1  # 整形的单值特征做个embedding\n",
    "            m = nn.Embedding(data.max() + 2, feed_dict[column], padding_idx=-1)\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        module_dict[column] = m  # 不同的特征名字对应不同的处理moderl 这里或许可以加FM进去\n",
    "    if textset is not None:\n",
    "        for column, field in textset.fields.items():\n",
    "            if field.vocab.vectors:\n",
    "                module_dict[column] = BagOfWordsPretrained(field,feed_dict[column])\n",
    "            else:\n",
    "                module_dict[column] = BagOfWords(field,feed_dict[column])\n",
    "    return module_dict\n",
    "class pleLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, mmoe_hidden_dim=128,num_task=4,n_expert=3,n_iid_expert=2,expert_activation=None):\n",
    "        super(pleLayer, self).__init__()\n",
    "         # experts\n",
    "        self.num_task=num_task\n",
    "        self.expert_activation = expert_activation\n",
    "        self.experts = torch.nn.Parameter(torch.rand(hidden_size, mmoe_hidden_dim, n_expert).cuda(), requires_grad=True)\n",
    "        self.experts.data.normal_(0, 1)\n",
    "        self.experts_bias = torch.nn.Parameter(torch.rand(mmoe_hidden_dim, n_expert).cuda(), requires_grad=True)\n",
    "        ## iid experts  (对于每个任务来说都有自己独立的专家)\n",
    "        self.iid_experts=[torch.nn.Parameter(torch.rand(hidden_size, mmoe_hidden_dim, n_iid_expert).cuda(), requires_grad=True) for _ in range(num_task)]\n",
    "        self.iid_experts=[iid_expert.data.normal_(0, 1) for iid_expert in self.iid_experts]\n",
    "        self.iid_experts_bias = [torch.nn.Parameter(torch.rand(mmoe_hidden_dim,n_iid_expert ).cuda(), requires_grad=True) for _ in range(num_task)]\n",
    "        # gates\n",
    "        self.gates = [torch.nn.Parameter(torch.rand(hidden_size, n_expert+n_iid_expert), requires_grad=True).cuda() for _ in range(num_task)]\n",
    "        for gate in self.gates:\n",
    "            gate.data.normal_(0, 1)\n",
    "        self.gates_bias = [torch.nn.Parameter(torch.rand(n_expert+n_iid_expert), requires_grad=True).cuda() for _ in range(num_task)]\n",
    "        for i in range(num_task):\n",
    "            setattr(self, 'task_{}_dnn'.format(i+1),DNN(mmoe_hidden_dim,(128,128),dropout_rate=0.2,l2_reg=1e-4,use_bn=True))\n",
    "    def forward(self,x):\n",
    "         # mmoe\n",
    "        experts_out = torch.einsum('ij, jkl -> ikl', x, self.experts) # batch * mmoe_hidden_size * num_experts\n",
    "        experts_out += self.experts_bias\n",
    "        if self.expert_activation is not None:\n",
    "            experts_out = self.expert_activation(experts_out)\n",
    "        # iid_experts：\n",
    "        iid_experts_out=list()\n",
    "        for ii in range(self.num_task):\n",
    "             iid_experts_out.append(torch.einsum('ij, jkl -> ikl', x, self.iid_experts[ii])+self.iid_experts_bias[ii])\n",
    "        \n",
    "        gates_out = list()\n",
    "        for idx, gate in enumerate(self.gates):\n",
    "            gate_out = torch.einsum('ab, bc -> ac',x, gate) # batch * num_experts\n",
    "            if self.gates_bias:\n",
    "                gate_out += self.gates_bias[idx]\n",
    "            gate_out = nn.Softmax(dim=-1)(gate_out)\n",
    "            gates_out.append(gate_out)\n",
    "\n",
    "        outs = list()\n",
    "        for idx,gate_output in enumerate(gates_out):\n",
    "            expanded_gate_output = torch.unsqueeze(gate_output, 1) # batch * 1 * num_experts\n",
    "            cat_experts=torch.cat([iid_experts_out[idx],experts_out],axis=-1)\n",
    "            weighted_expert_output =cat_experts * expanded_gate_output.expand_as(cat_experts) # batch * mmoe_hidden_size * num_experts\n",
    "            outs.append(torch.sum(weighted_expert_output, 2)) # batch * mmoe_hidden_size\n",
    "          # task tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_task):\n",
    "            oo = outs[i]\n",
    "            mod=getattr(self, 'task_{}_dnn'.format(i+1))\n",
    "            oo = mod(oo)\n",
    "            task_outputs.append(oo)\n",
    "        \n",
    "        return task_outputs\n",
    "\n",
    "class MMOELayer(nn.Module):\n",
    "    def __init__(self, hidden_size, mmoe_hidden_dim=128,num_task=4,n_expert=3,expert_activation=None):\n",
    "        super(MMOELayer, self).__init__()\n",
    "         # experts\n",
    "        self.num_task=num_task\n",
    "        self.expert_activation = expert_activation\n",
    "        self.experts = torch.nn.Parameter(torch.rand(hidden_size, mmoe_hidden_dim, n_expert).cuda(), requires_grad=True)\n",
    "        self.experts.data.normal_(0, 1)\n",
    "        self.experts_bias = torch.nn.Parameter(torch.rand(mmoe_hidden_dim, n_expert).cuda(), requires_grad=True)\n",
    "        # gates\n",
    "        self.gates = [torch.nn.Parameter(torch.rand(hidden_size, n_expert), requires_grad=True).cuda() for _ in range(num_task)]\n",
    "        for gate in self.gates:\n",
    "            gate.data.normal_(0, 1)\n",
    "        self.gates_bias = [torch.nn.Parameter(torch.rand(n_expert), requires_grad=True).cuda() for _ in range(num_task)]\n",
    "        for i in range(num_task):\n",
    "            setattr(self, 'task_{}_dnn'.format(i+1),DNN(mmoe_hidden_dim,(128,128),dropout_rate=0.2,l2_reg=1e-4,use_bn=True))\n",
    "    def forward(self,x):\n",
    "         # mmoe\n",
    "        experts_out = torch.einsum('ij, jkl -> ikl', x, self.experts) # batch * mmoe_hidden_size * num_experts\n",
    "        experts_out += self.experts_bias\n",
    "        if self.expert_activation is not None:\n",
    "            experts_out = self.expert_activation(experts_out)\n",
    "        \n",
    "        gates_out = list()\n",
    "        for idx, gate in enumerate(self.gates):\n",
    "            gate_out = torch.einsum('ab, bc -> ac',x, gate) # batch * num_experts\n",
    "            if self.gates_bias:\n",
    "                gate_out += self.gates_bias[idx]\n",
    "            gate_out = nn.Softmax(dim=-1)(gate_out)\n",
    "            gates_out.append(gate_out)\n",
    "\n",
    "        outs = list()\n",
    "        for gate_output in gates_out:\n",
    "            expanded_gate_output = torch.unsqueeze(gate_output, 1) # batch * 1 * num_experts\n",
    "            weighted_expert_output = experts_out * expanded_gate_output.expand_as(experts_out) # batch * mmoe_hidden_size * num_experts\n",
    "            outs.append(torch.sum(weighted_expert_output, 2)) # batch * mmoe_hidden_size\n",
    "          # task tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_task):\n",
    "            oo = outs[i]\n",
    "            mod=getattr(self, 'task_{}_dnn'.format(i+1))\n",
    "            oo = mod(oo)\n",
    "            task_outputs.append(oo)\n",
    "        \n",
    "        return task_outputs\n",
    "\n",
    "class HighwayMLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 gate_bias=-3,\n",
    "                 activation_function=nn.functional.relu,\n",
    "                 gate_activation=nn.functional.softmax):\n",
    "\n",
    "        super(HighwayMLP, self).__init__()\n",
    "\n",
    "        self.activation_function = activation_function\n",
    "        self.gate_activation = gate_activation\n",
    "\n",
    "        self.normal_layer = DNN(input_size,(input_size,input_size,input_size),dropout_rate=0.1)\n",
    "\n",
    "        self.gate_layer = nn.Linear(input_size,input_size)\n",
    "\n",
    "        self.gate_layer.bias.data.fill_(gate_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        normal_layer_result = self.activation_function(self.normal_layer(x))\n",
    "        gate_layer_result = self.gate_activation(self.gate_layer(x))\n",
    "\n",
    "        multiplyed_gate_and_normal = torch.mul(normal_layer_result, gate_layer_result)\n",
    "        multiplyed_gate_and_input = torch.mul((1 - gate_layer_result), x)\n",
    "\n",
    "        return torch.add(multiplyed_gate_and_normal,\n",
    "                         multiplyed_gate_and_input)\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, optimizer, k=5, alpha=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "\n",
    "    def update(self, group):\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "\n",
    "    def update_lookahead(self):\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self):\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {(id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "class WarmupLinearSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then linear decay.\n",
    "        Multiplies the learning rate defined in the optimizer by a dynamic variable determined by the current step.\n",
    "        Linearly increases the multiplicative variable from 0. to 1. over `warmup_steps` training steps.\n",
    "        Linearly decreases the multiplicative variable from 1. to 0. over remaining `t_total - warmup_steps` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.t_total = t_total\n",
    "        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1, self.warmup_steps))\n",
    "        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size,1)\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (T,B,H)\n",
    "        :param src_len:\n",
    "            used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''   \n",
    "        att=self.attn(x)\n",
    "        att=F.tanh(att)\n",
    "        att=F.softmax(att,1)\n",
    "        att_x=att*x\n",
    "        return att_x.sum(1)   \n",
    "# class Attn(nn.Module):\n",
    "#     def __init__(self,hidden_size):\n",
    "#         super(Attn, self).__init__()\n",
    "#         self.attn = nn.Linear(hidden_size,3)\n",
    "#     def forward(self, x):\n",
    "#         '''\n",
    "#         :param hidden: \n",
    "#             previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "#         :param encoder_outputs:\n",
    "#             encoder outputs from Encoder, in shape (T,B,H)\n",
    "#         :param src_len:\n",
    "#             used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
    "#         :return\n",
    "#             attention energies in shape (B,T)\n",
    "#         '''   \n",
    "#         att=self.attn(x)\n",
    "#         att=F.normalize(att)\n",
    "#         att=F.softmax(att,1)\n",
    "#         att_x=sum([(x*att[:,:,i:i+1]).sum(1)  for i in range(3)])/3\n",
    "# #         att_x=att*x\n",
    "#         return att_x#.sum(1)   \n",
    "class AdamW(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.0, correct_bias=True):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n",
    "                        correct_bias=correct_bias)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "                exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1.0 - beta2, grad, grad)\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                step_size = group['lr']\n",
    "                if group['correct_bias']:  # No bias correction for Bert\n",
    "                    bias_correction1 = 1.0 - beta1 ** state['step']\n",
    "                    bias_correction2 = 1.0 - beta2 ** state['step']\n",
    "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "                if group['weight_decay'] > 0.0:\n",
    "                    p.data.add_(-group['lr'] * group['weight_decay'], p.data)\n",
    "        return loss\n",
    "    \n",
    "def build_optimizer(model, train_steps, learning_rate):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False, eps=1e-8)\n",
    "    optimizer = Lookahead(optimizer, 5, 1)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=train_steps * 0.1, t_total=train_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def n_evaluate_nn(val_df,action_list,batch_size=512):\n",
    "    model.eval()\n",
    "    leng=len(val_df)\n",
    "    val_src=val_df['userid'].apply(lambda x:userid2nid[x]).tolist()\n",
    "    val_dst=val_df['feedid'].apply(lambda x:feedid2nid[x]).tolist()\n",
    "    val_dense=torch.from_numpy(val_df[feat].values).float()\n",
    "#     regs=torch.from_numpy(train_ratings['reg'].values).float()\n",
    "    val_pred=[]\n",
    "    all_aucs=[]\n",
    "    weights=[0.30769231, 0.23076923, 0.15384615, 0.07692308, 0.07692308,0.07692308, 0.07692308]\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0,leng//batch_size+1)):\n",
    "            #         print(i*batch_size,(i+1)*batch_size)\n",
    "            batch_src=val_src[i*batch_size:(i+1)*batch_size]\n",
    "            batch_dst=val_dst[i*batch_size:(i+1)*batch_size]\n",
    "            batch_dense=val_dense[i*batch_size:(i+1)*batch_size].cuda()\n",
    "            pred=model(batch_src,batch_dst,batch_dense)\n",
    "            val_pred.append(torch.cat(pred,axis=-1).sigmoid().cpu().numpy())\n",
    "        val_pred=np.concatenate(val_pred,axis=0)\n",
    "        for i,action in enumerate(action_list):\n",
    "            val_df['pred_'+action]=val_pred[:,i]\n",
    "            label_nunique = val_df.groupby(by='userid')[action].transform('nunique')\n",
    "            tmp_df = val_df[label_nunique == 2]\n",
    "            aucs = tmp_df.groupby(by='userid').apply(\n",
    "                lambda x: roc_auc_score(x[action].values, x['pred_'+action].values))\n",
    "            all_aucs.append(np.mean(aucs))\n",
    "            print('val %s uauc:'%action,np.mean(aucs))\n",
    "            print('val %s auc:'%action,roc_auc_score(val_df[action].values,val_pred[:,i]))\n",
    "        print('score uauc:',sum([all_aucs[i]*weights[i] for i in range(len(action_list))]))\n",
    "        np.save('./my_result.npy',np.asarray(all_aucs))\n",
    "def evaluate_nn(val_df,action,batch_size=512):\n",
    "    model.eval()\n",
    "    leng=len(val_df)\n",
    "    val_src=val_df['userid'].apply(lambda x:userid2nid[x]).tolist()\n",
    "    val_dst=val_df['feedid'].apply(lambda x:feedid2nid[x]).tolist()\n",
    "    val_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0,leng//batch_size+1)):\n",
    "            #         print(i*batch_size,(i+1)*batch_size)\n",
    "            batch_src=val_src[i*batch_size:(i+1)*batch_size]\n",
    "            batch_dst=val_dst[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            pred=model(batch_src,batch_dst)\n",
    "\n",
    "            val_pred.append(pred.sigmoid().view(-1).cpu().numpy())\n",
    "        val_pred=np.concatenate(val_pred,axis=-1)\n",
    "        val_df['pred_'+action]=val_pred\n",
    "        label_nunique = val_df.groupby(by='userid')[action].transform('nunique')\n",
    "        tmp_df = val_df[label_nunique == 2]\n",
    "        \n",
    "        aucs = tmp_df.groupby(by='userid').apply(\n",
    "            lambda x: roc_auc_score(x[action].values, x['pred_'+action].values))\n",
    "        print('val uauc:',np.mean(aucs))\n",
    "        print('val auc:',roc_auc_score(val_df[action].values,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b526066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T05:00:18.134426Z",
     "start_time": "2021-06-30T05:00:15.548831Z"
    }
   },
   "outputs": [],
   "source": [
    "for f,d in user_data.items():\n",
    "    user_data[f]=d.cuda()\n",
    "    \n",
    "for f,d in feed_data.items():\n",
    "    feed_data[f]=d.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0cbd1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T05:00:25.528556Z",
     "start_time": "2021-06-30T05:00:18.295409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_day=14\n",
    "train_ratings=ratings[(ratings.date_<max_day)]\n",
    "val_ratings=ratings[ratings.date_==max_day]\n",
    "del ratings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30da452d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5a9579fca0d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPREDICT_LIST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mregs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size=4096*4\n",
    "epochs=2\n",
    "trn_dense=torch.from_numpy(train_ratings[feat].values).float()\n",
    "src=train_ratings['userid'].apply(lambda x: userid2nid[x]).values\n",
    "dst=train_ratings['feedid'].apply(lambda x: feedid2nid[x]).values\n",
    "labels=torch.from_numpy(train_ratings[PREDICT_LIST].values).float()\n",
    "regs=torch.from_numpy(train_ratings['reg'].values).float()\n",
    "# del ratings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18050f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T05:57:40.826101Z",
     "start_time": "2021-06-30T05:00:25.967938Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: ----0--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4094 [00:00<1:05:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 3.2645654678344727\n",
      "train read_comment auc: 0.5966964294291608\n",
      "train like auc: 0.5091863340987751\n",
      "train click_avatar auc: 0.4198478954292908\n",
      "train forward auc: 0.4797088131993793\n",
      "train comment auc: 0.2511386531534282\n",
      "train follow auc: 0.4226077796775769\n",
      "train favorite auc: 0.5661607800097261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1001/4094 [13:59<44:16,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.32277464866638184\n",
      "train read_comment auc: 0.937808891431875\n",
      "train like auc: 0.8539312367312937\n",
      "train click_avatar auc: 0.8675985799416762\n",
      "train forward auc: 0.8937685233448127\n",
      "train comment auc: 0.7880587445041525\n",
      "train follow auc: 0.8744052014680488\n",
      "train favorite auc: 0.9687620573693588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1746/4094 [24:24<32:51,  1.19it/s]"
     ]
    }
   ],
   "source": [
    "model = Model(user_data,feed_data\n",
    "             ,feed_embed=feed_emb,graph_emb=graph_emb) \n",
    "model=model.cuda()\n",
    "# model = nn.DataParallel(model)\n",
    "train_steps = int(len(train_ratings) * epochs / batch_size) + 1\n",
    "optimizer, scheduler = build_optimizer(model, train_steps, learning_rate=1e-3)\n",
    "all_pred=[]\n",
    "criti=nn.BCEWithLogitsLoss()\n",
    "reg_criti=nn.MSELoss()\n",
    "n_pos=len(train_ratings)\n",
    "batch_index=np.arange(n_pos) # 生成正样本的index\n",
    "for epoch in range(epochs):\n",
    "    print('epoch: ----%d--'%epoch)\n",
    "    random.shuffle(batch_index) \n",
    "    epoch_loss=0\n",
    "    model.train()\n",
    "    for ind in tqdm(range(0,n_pos//batch_size+1)):\n",
    "        batch=batch_index[ind*batch_size:(ind+1)*batch_size]\n",
    "        batch_dense=trn_dense[batch].cuda()\n",
    "        batch_src=src[batch]\n",
    "        batch_dst=dst[batch]\n",
    "        logits = model(batch_src,batch_dst,batch_dense)\n",
    "        batch_label=labels[batch].cuda()\n",
    "        batch_reg=regs[batch].cuda()\n",
    "        loss=criti(logits[0][:,0],batch_label[:,0])*0.8+criti(logits[1][:,0],batch_label[:,1])*0.8+\\\n",
    "        criti(logits[2][:,0],batch_label[:,2])*0.4+criti(logits[3][:,0],batch_label[:,3])*0.4+reg_criti(logits[7][:,0],batch_reg)*0.6+\\\n",
    "        criti(logits[4][:,0],batch_label[:,4])*0.3+criti(logits[5][:,0],batch_label[:,5])*0.3+criti(logits[6][:,0],batch_label[:,6])*0.3\n",
    "        epoch_loss+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if ind%1000==0:\n",
    "            print('binary loss:',loss.item())\n",
    "            batch_label=batch_label.cpu().numpy()\n",
    "            pred=torch.cat(logits,axis=-1).sigmoid().detach().cpu().numpy()\n",
    "#             pred=logits.sigmoid().detach().cpu().numpy()\n",
    "            for ii,aa in enumerate(PREDICT_LIST):\n",
    "                try:\n",
    "                    print('train %s auc:'%aa,roc_auc_score(batch_label[:,ii],pred[:,ii]))\n",
    "                except:\n",
    "                    print( aa+'fial to auc !!!')\n",
    "                    continue\n",
    "    print('epoch %d  loss: %f '%(epoch,epoch_loss/(len(batch_index)//batch_size+1)))\n",
    "    n_evaluate_nn(val_df=val_ratings,action_list=PREDICT_LIST,batch_size=4096*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc351e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val read_comment uauc: 0.6532240277707273\n",
    "val read_comment auc: 0.9360819237021545\n",
    "val like uauc: 0.6409431245553913\n",
    "val like auc: 0.8532987743342961\n",
    "val click_avatar uauc: 0.7393548341421335\n",
    "val click_avatar auc: 0.8704235398899445\n",
    "val forward uauc: 0.7299854864008402\n",
    "val forward auc: 0.8947281151250339\n",
    "val comment uauc: 0.6122907155801588\n",
    "val comment auc: 0.8993796307709051\n",
    "val follow uauc: 0.7222546032289817\n",
    "val follow auc: 0.8932625954223432\n",
    "val favorite uauc: 0.7633000543493066\n",
    "val favorite auc: 0.9479415454555266\n",
    "score uauc: 0.6801743155327246\n",
    "    \n",
    "val read_comment uauc: 0.6572729257828056\n",
    "val read_comment auc: 0.9367540800699401\n",
    "val like uauc: 0.644905514140168\n",
    "val like auc: 0.8519366965244407\n",
    "val click_avatar uauc: 0.7428537800440949\n",
    "val click_avatar auc: 0.8688636546947295\n",
    "val forward uauc: 0.7330386642442374\n",
    "val forward auc: 0.8925939229310389\n",
    "val comment uauc: 0.6205971813788604\n",
    "val comment auc: 0.8956591160424929\n",
    "val follow uauc: 0.7287694093988702\n",
    "val follow auc: 0.8857541009071324\n",
    "val favorite uauc: 0.7698880762786124\n",
    "val favorite auc: 0.9455850100591795\n",
    "score uauc: 0.6847545559352824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7b807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T02:01:58.956237Z",
     "start_time": "2021-06-28T02:01:54.361938Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, './model_weight/my_deep_v2_v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a52c7e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T04:29:40.220242Z",
     "start_time": "2021-06-30T04:29:39.683400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2981/2981 [05:08<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val read_comment uauc: 0.6562008546758703\n",
      "val read_comment auc: 0.9359379390891691\n",
      "val like uauc: 0.6425112812710617\n",
      "val like auc: 0.8514447212649744\n",
      "val click_avatar uauc: 0.7396113431487045\n",
      "val click_avatar auc: 0.8658891373574445\n",
      "val forward uauc: 0.7297673493048045\n",
      "val forward auc: 0.8908334243895446\n",
      "val comment uauc: 0.6119609371008592\n",
      "val comment auc: 0.8901223560947193\n",
      "val follow uauc: 0.7287727331714252\n",
      "val follow auc: 0.8800854280745978\n",
      "val favorite uauc: 0.7616945036177958\n",
      "val favorite auc: 0.9433597361780205\n",
      "score uauc: 0.6818273508905482\n"
     ]
    }
   ],
   "source": [
    "n_evaluate_nn(val_df=val_ratings,action_list=PREDICT_LIST,batch_size=4096*3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48307b4c",
   "metadata": {},
   "source": [
    "(加 hash )  （不加hash，加平滑）       (bn)\n",
    "0.6269         0.631            0.631  0.635\n",
    "0.615          0.617            0.612  0.620\n",
    "0.686          0.701            0.705  0.710\n",
    "0.688          0.689                   0.701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9a065ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T06:02:55.469631Z",
     "start_time": "2021-06-30T05:59:08.054904Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4899/4899 [06:22<00:00, 12.82it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred=test_pred_func(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "433e9976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T06:03:33.182241Z",
     "start_time": "2021-06-30T06:03:31.297980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "test_a[PREDICT_LIST]=test_pred[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8f768c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T06:09:21.367037Z",
     "start_time": "2021-06-30T06:09:21.352623Z"
    }
   },
   "outputs": [],
   "source": [
    "sub=test_a[['userid','feedid']+PREDICT_LIST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "141d454d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T06:10:06.353523Z",
     "start_time": "2021-06-30T06:10:02.679891Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('./upload/deep_v2_v1_sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22d456c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a=pd.read_csv('./wbdc2021/data/wedata/wechat_algo_data2/test_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "995978f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T02:36:53.653330Z",
     "start_time": "2021-06-28T02:36:53.529485Z"
    }
   },
   "outputs": [],
   "source": [
    "test_a=df[df.date_==15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c6a38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:12:06.399917Z",
     "start_time": "2021-06-30T11:12:06.396551Z"
    }
   },
   "outputs": [],
   "source": [
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1e87cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:15:20.167859Z",
     "start_time": "2021-06-30T11:15:19.175342Z"
    }
   },
   "outputs": [],
   "source": [
    "# sub1=pd.read_csv('./upload/deep_v2_ple.csv')\n",
    "# sub1=pd.read_csv('./upload/deep_v2_v1_sample.csv')\n",
    "sub3=pd.read_csv('./upload/sub_lgb2021.csv')\n",
    "# sub1=pd.read_csv('./upload/ensemble2.csv')\n",
    "# sub1=pd.read_csv('./upload/sample_deep_v2_v2.csv')\n",
    "# sub1=pd.read_csv('./upload/modefile_allem_0.6952.csv')\n",
    "# sub1=pd.read_csv('./upload/sample_deep_v2_v1_ratings.csv')\n",
    "# sub1=pd.read_csv('./upload/deep_v2_v1_all_process.csv')\n",
    "# sub1=pd.read_csv('./upload/allemb_deep_v2_v1_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50958d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:15:20.549795Z",
     "start_time": "2021-06-30T11:15:20.526185Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred=sub1[PREDICT_LIST].values*0.1+sub2[PREDICT_LIST].values*0.1+\\\n",
    "sub4[PREDICT_LIST].values*0.3+sub5[PREDICT_LIST].values*0.1+sub6[PREDICT_LIST].values*0.1+\\\n",
    "sub7[PREDICT_LIST].values*0.1+sub8[PREDICT_LIST].values*0.1+sub9[PREDICT_LIST].values*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fac2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred+=sub1[PREDICT_LIST].values*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cab0e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[:,1]=test_pred[:,1]*0.92+sub3['like'].values*0.08\n",
    "test_pred[:,4]=test_pred[:,4]*0.96+sub3['comment'].values*0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1dfb32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:15:21.482688Z",
     "start_time": "2021-06-30T11:15:21.365371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_a=pd.read_csv('./wbdc2021/data/wedata/wechat_algo_data2/test_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a17cfc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:15:25.244362Z",
     "start_time": "2021-06-30T11:15:25.230619Z"
    }
   },
   "outputs": [],
   "source": [
    "sub=sub1[['userid','feedid']]\n",
    "for i in range(len(PREDICT_LIST)):\n",
    "    sub[PREDICT_LIST[i]]=test_pred[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cfa59cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:15:58.025568Z",
     "start_time": "2021-06-30T11:15:54.539528Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('./upload/ensenmbe3_contu_more.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50cfb326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T02:38:35.106153Z",
     "start_time": "2021-06-28T02:38:35.079421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-bc76750da07e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub['read_comment']=(sub1['read_comment']+sub2['read_comment']).values/2\n",
      "<ipython-input-52-bc76750da07e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub['like']=(sub1['like']+sub2['like']).values/2\n",
      "<ipython-input-52-bc76750da07e>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub['click_avatar']=(sub1['click_avatar']+sub2['click_avatar']).values/2\n",
      "<ipython-input-52-bc76750da07e>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub['forward']=(sub2['forward']+sub1['forward']).values/2\n"
     ]
    }
   ],
   "source": [
    "sub['read_comment']=(sub1['read_comment']+sub2['read_comment']).values/2\n",
    "sub['like']=(sub1['like']+sub2['like']).values/2\n",
    "sub['click_avatar']=(sub1['click_avatar']+sub2['click_avatar']).values/2\n",
    "sub['forward']=(sub2['forward']+sub1['forward']).values/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11c54615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T02:38:56.204885Z",
     "start_time": "2021-06-28T02:38:53.685279Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('my_deep_ensemble_21.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "220f1471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-21T11:18:30.123183Z",
     "start_time": "2021-06-21T11:18:30.067995Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4657a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv('./upload/deep_v2+v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d77268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>feedid</th>\n",
       "      <th>read_comment</th>\n",
       "      <th>like</th>\n",
       "      <th>click_avatar</th>\n",
       "      <th>forward</th>\n",
       "      <th>comment</th>\n",
       "      <th>follow</th>\n",
       "      <th>favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175282</td>\n",
       "      <td>50458</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80036</td>\n",
       "      <td>42329</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145791</td>\n",
       "      <td>85242</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28430</td>\n",
       "      <td>9425</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.069001</td>\n",
       "      <td>0.055966</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44393</td>\n",
       "      <td>11866</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  feedid  read_comment      like  click_avatar   forward   comment  \\\n",
       "0  175282   50458      0.013006  0.004985      0.000409  0.019743  0.000052   \n",
       "1   80036   42329      0.004962  0.003664      0.026879  0.001048  0.000009   \n",
       "2  145791   85242      0.000127  0.002968      0.001970  0.000237  0.000005   \n",
       "3   28430    9425      0.000049  0.002507      0.069001  0.055966  0.000152   \n",
       "4   44393   11866      0.002277  0.000740      0.001726  0.001206  0.000001   \n",
       "\n",
       "     follow  favorite  \n",
       "0  0.000007  0.000011  \n",
       "1  0.001628  0.000312  \n",
       "2  0.000068  0.000078  \n",
       "3  0.003369  0.000100  \n",
       "4  0.000031  0.000041  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13afa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a=pd.read_csv('./wbdc2021/data/wedata/wechat_algo_data2/test_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fb41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_py3",
   "language": "python",
   "name": "conda_pytorch_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
