{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa9f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import dgl.function as fn\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import auc,roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.models.deepfm import FM,DNN\n",
    "from deepctr_torch.layers  import CIN,InteractingLayer,CrossNet,CrossNetMix\n",
    "from deepctr_torch.models.basemodel import *\n",
    "from collections import defaultdict\n",
    "from torch.optim import Optimizer\n",
    "import torchtext\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from train.model.trans1 import * # 转入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8ca76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.05 Mb, 7.05 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:10,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.54 Mb, 3.54 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:05<00:10,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 Mb, 0.65 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:09<00:08,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397.81 Mb, 1397.81 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:01<00:35, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820.76 Mb, 820.76 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:33<00:21, 21.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820.76 Mb, 820.76 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:03<00:00, 20.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n",
      "1532.83 Mb, 940.79 Mb (38.62 %)\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH='../data/'\n",
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']\n",
    "test_a=pd.read_csv(ROOT_PATH+'wedata/wechat_algo_data2/test_a.csv')\n",
    "feed_info=pd.read_pickle(ROOT_PATH+'tmp/cat_feed_info.pkl')\n",
    "userid2nid=pickle.load(open(ROOT_PATH+'tmp/userid2nid.pkl','rb'))\n",
    "feedid2nid=pickle.load(open(ROOT_PATH+'tmp/feedid2nid.pkl','rb'))\n",
    "test_a=test_a.merge(feed_info[['feedid', 'authorid', 'videoplayseconds','manual_keyword_id1','manual_tag_id1']], on='feedid', how='left')\n",
    "test_a['date_']=15 # 由于 复赛数据B榜不可见 这里就不放入a榜数据使用\n",
    "max_day=15\n",
    "for stat_cols in tqdm([['userid'],['feedid'],['authorid'], ['userid', 'authorid'],['userid', 'manual_tag_id1'],\n",
    "        ['userid','manual_keyword_id1']]):\n",
    "    f = '_'.join(stat_cols)\n",
    "#     tmp.to_pickle('./tmp/{}_feat_{}.pkl'.format(target_day,'_'.join(stat_cols)))\n",
    "    tmp=pd.read_pickle(ROOT_PATH+'tmp/{}_feat_{}.pkl'.format(15,'_'.join(stat_cols)))\n",
    "    tmp=reduce_mem(tmp)\n",
    "    test_a = test_a.merge(tmp, on=stat_cols + ['date_'], how='left')\n",
    "    mean_tmp=pickle.load(open(ROOT_PATH+'tmp/{}_feat_mean.pkl'.format('_'.join(stat_cols)),'rb'))\n",
    "    for kk,vv in mean_tmp.items():\n",
    "        test_a[kk]=test_a[kk].fillna(vv) # 填充均值\n",
    "test_a=reduce_mem(test_a)\n",
    "gc.collect()\n",
    "feat=pickle.load(open(ROOT_PATH+'tmp/feat_list.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0511c16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:07<00:00, 12.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_columnsillna(-1,inplace=True)\n",
    "normolizer_dict=pickle.load(open(ROOT_PATH+'tmp/normolizer_dict.pkl','rb'))\n",
    "for f in tqdm(feat):\n",
    "    tmp=test_a[f].values.astype('float16').clip(-1,1e8)\n",
    "    tmp_max=normolizer_dict[f+'_max'] # 这里 或许我得保留均值和方差\n",
    "    tmp_min=normolizer_dict[f+'_min']\n",
    "    test_a[f]=((tmp-tmp_min)/tmp_max).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04638297",
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_emb=np.load(ROOT_PATH+'tmp/feed_emb.npy')\n",
    "item_texts=pickle.load(open(ROOT_PATH+'tmp/item_texts.pkl','rb'))\n",
    "feed_data=pickle.load(open(ROOT_PATH+'tmp/feed_data.pkl','rb'))\n",
    "user_data=pickle.load(open(ROOT_PATH+'tmp/user_data.pkl','rb'))\n",
    "graph_emb=np.concatenate([np.load(ROOT_PATH+'tmp/grap_embedding32_sg2.npy'),np.load(ROOT_PATH+'tmp/grap_embedding32_hs2.npy')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01ad355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda x: x.split(' ')\n",
    "fields = {}\n",
    "examples = []\n",
    "for key, texts in item_texts.items():\n",
    "    if  key in ['ocr','asr','description']:\n",
    "        fields[key] = torchtext.data.Field(include_lengths=True, lower=True,tokenize=tokenize, batch_first=True, fix_length=64)\n",
    "    else:\n",
    "        fields[key] = torchtext.data.Field(include_lengths=True, lower=True,tokenize=tokenize, batch_first=True, fix_length=5)\n",
    "for i in range(len(item_texts['ocr'])):\n",
    "    example = torchtext.data.Example.fromlist(\n",
    "        [item_texts[key][i] for key in item_texts.keys()],\n",
    "        [(key, fields[key]) for key in item_texts.keys()])  #( [feat1,feat2], [(key1,field1),(key2,field2)] )\n",
    "    examples.append(example)\n",
    "textset = torchtext.data.Dataset(examples, fields)\n",
    "for key, field in fields.items():\n",
    "    field.build_vocab(getattr(textset, key))\n",
    "for field_name, field in textset.fields.items():\n",
    "    examples = [getattr(textset[i], field_name) for i in range(len(textset.examples))]\n",
    "\n",
    "    tokens, lengths = field.process(examples)\n",
    "\n",
    "    if not field.batch_first:\n",
    "        tokens = tokens.t()\n",
    "    # 给feed +上文本向量\n",
    "    feed_data[field_name] = tokens\n",
    "\n",
    "for f,d in user_data.items():\n",
    "    user_data[f]=d.to(torch.device('cuda'))\n",
    "    \n",
    "for f,d in feed_data.items():\n",
    "    feed_data[f]=d.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12639a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5a4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(user_data,feed_data,textset\n",
    "#              ,feed_embed=feed_emb,graph_emb=graph_emb) \n",
    "model = torch.load('../data/model/trans.pth')\n",
    "# model.load_state_dict(model_dict.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c470b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1039 [00:00<?, ?it/s]/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 1039/1039 [01:11<00:00, 14.52it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred=test_pred_func(model,test_a,userid2nid,feedid2nid,feat)\n",
    "for i,f in enumerate(PREDICT_LIST):\n",
    "    test_a[f]=test_pred[:,i]\n",
    "sub=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "\n",
    "sub.to_csv('../../upload/model2_posemb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a42cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='../data/'\n",
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']\n",
    "test_a=pd.read_csv(ROOT_PATH+'wedata/wechat_algo_data2/test_a.csv')\n",
    "userid2nid=pickle.load(open(ROOT_PATH+'tmp/userid2nid.pkl','rb'))\n",
    "feedid2nid=pickle.load(open(ROOT_PATH+'tmp/feedid2nid.pkl','rb'))\n",
    "test_a['date_']=15 # 由于 复赛数据B榜不可见 这里就不放入a榜数据使用\n",
    "hist_seq=torch.from_numpy(np.load(ROOT_PATH+'tmp/hist_list1.npy')).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31b5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src=torch.from_numpy(test_a['userid'].apply(lambda x: userid2nid[x]).values).long()\n",
    "dst=torch.from_numpy(test_a['feedid'].apply(lambda x: feedid2nid[x]).values).long()\n",
    "hist_id=torch.from_numpy((test_a['date_'].values-1)*len(userid2nid)).long()+src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6356727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1039 [00:00<?, ?it/s]/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 1039/1039 [01:38<00:00, 10.60it/s]\n"
     ]
    }
   ],
   "source": [
    " model.eval()\n",
    "batch_size=4096\n",
    "leng=len(test_a)\n",
    "val_pred=[]\n",
    "all_aucs=[]\n",
    "weights=[0.30769231, 0.23076923, 0.15384615, 0.07692308, 0.07692308,0.07692308, 0.07692308]\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0,leng//batch_size+1)):\n",
    "        #         print(i*batch_size,(i+1)*batch_size)\n",
    "        batch_src=src[i*batch_size:(i+1)*batch_size]\n",
    "        batch_dst=dst[i*batch_size:(i+1)*batch_size]\n",
    "        batch_hist=hist_seq[hist_id[i*batch_size:(i+1)*batch_size]]\n",
    "        pred=model(batch_src,batch_dst,batch_hist[:,:-1],batch_hist[:,-1:].cuda())\n",
    "        val_pred.append(torch.cat(pred,axis=-1).sigmoid().cpu().numpy())\n",
    "    val_pred=np.concatenate(val_pred,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff186ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(PREDICT_LIST):\n",
    "    test_a[f]=val_pred[:,i]\n",
    "sub=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "\n",
    "sub.to_csv('../../upload/trans.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbfa87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedb32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1=pd.read_csv('../../upload/dayemb_96feat_ratings_0.6978.csv')\n",
    "sub2=pd.read_csv('../../upload/trans_0.695.csv')\n",
    "# sub3=pd.read_csv('../../upload/ensenmbe3_contu_more.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f78039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_LIST = [\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']#\n",
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57da4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([sub3,sub2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fbba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=sub1[PREDICT_LIST].values*0.5+sub2[PREDICT_LIST].values*0.5#+sub3[PREDICT_LIST].values*0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b891d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1[PREDICT_LIST]=tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f206e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.to_csv('../../upload/trans+dayemb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87bd230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(ROOT_PATH+'tmp/sample_feat_df.pkl').iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ee7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 61/92 [00:04<00:02, 12.36it/s]/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "100%|██████████| 92/92 [00:06<00:00, 14.20it/s]\n"
     ]
    }
   ],
   "source": [
    "test_a.fillna(-1,inplace=True)\n",
    "for f in tqdm(feat):\n",
    "    tmp=test_a[f].values.astype('float16').clip(-1,1e8)\n",
    "    tmp_max=tmp.max() # 这里 或许我得保留均值和方差\n",
    "    tmp_min=tmp.min()\n",
    "    test_a[f]=((tmp-tmp_min)/tmp_max).astype('float16')\n",
    "# test_a.fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35bb4108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>feedid</th>\n",
       "      <th>read_comment</th>\n",
       "      <th>like</th>\n",
       "      <th>click_avatar</th>\n",
       "      <th>forward</th>\n",
       "      <th>comment</th>\n",
       "      <th>follow</th>\n",
       "      <th>favorite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175282</td>\n",
       "      <td>50458</td>\n",
       "      <td>2.116705e-02</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.016754</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.127469e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80036</td>\n",
       "      <td>42329</td>\n",
       "      <td>3.220625e-03</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>7.742712e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145791</td>\n",
       "      <td>85242</td>\n",
       "      <td>4.745018e-04</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1.777745e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28430</td>\n",
       "      <td>9425</td>\n",
       "      <td>2.364895e-04</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>0.033417</td>\n",
       "      <td>0.023833</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>3.379448e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44393</td>\n",
       "      <td>11866</td>\n",
       "      <td>8.018039e-04</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2.922827e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83947</td>\n",
       "      <td>8199</td>\n",
       "      <td>5.869880e-07</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9.888038e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147551</td>\n",
       "      <td>3310</td>\n",
       "      <td>1.400830e-04</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.515313e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128347</td>\n",
       "      <td>47645</td>\n",
       "      <td>1.845777e-02</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.165910e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>173771</td>\n",
       "      <td>109162</td>\n",
       "      <td>2.794791e-03</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>2.006952e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24614</td>\n",
       "      <td>69966</td>\n",
       "      <td>4.211445e-03</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.080539e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>189383</td>\n",
       "      <td>17576</td>\n",
       "      <td>1.089581e-06</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>4.805734e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200799</td>\n",
       "      <td>89186</td>\n",
       "      <td>3.780638e-03</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>8.183148e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>209203</td>\n",
       "      <td>30411</td>\n",
       "      <td>4.192377e-05</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>2.116532e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>118170</td>\n",
       "      <td>63953</td>\n",
       "      <td>4.097891e-06</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.014649</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>8.347884e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>122866</td>\n",
       "      <td>10474</td>\n",
       "      <td>1.817472e-03</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.432022e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userid  feedid  read_comment      like  click_avatar   forward   comment  \\\n",
       "0   175282   50458  2.116705e-02  0.008697      0.001345  0.016754  0.000004   \n",
       "1    80036   42329  3.220625e-03  0.003999      0.028065  0.000361  0.000013   \n",
       "2   145791   85242  4.745018e-04  0.003250      0.007136  0.000319  0.000103   \n",
       "3    28430    9425  2.364895e-04  0.012196      0.033417  0.023833  0.000216   \n",
       "4    44393   11866  8.018039e-04  0.001005      0.005653  0.000692  0.000004   \n",
       "5    83947    8199  5.869880e-07  0.001386      0.001197  0.000004  0.000004   \n",
       "6   147551    3310  1.400830e-04  0.000712      0.001187  0.000028  0.000005   \n",
       "7   128347   47645  1.845777e-02  0.010705      0.009865  0.000192  0.000119   \n",
       "8   173771  109162  2.794791e-03  0.001661      0.070240  0.000006  0.000074   \n",
       "9    24614   69966  4.211445e-03  0.003604      0.006716  0.000322  0.000042   \n",
       "10  189383   17576  1.089581e-06  0.003905      0.039626  0.000291  0.000003   \n",
       "11  200799   89186  3.780638e-03  0.001264      0.001706  0.000092  0.000016   \n",
       "12  209203   30411  4.192377e-05  0.011329      0.005417  0.000091  0.000082   \n",
       "13  118170   63953  4.097891e-06  0.002515      0.014649  0.004965  0.000074   \n",
       "14  122866   10474  1.817472e-03  0.009580      0.003291  0.000084  0.000008   \n",
       "\n",
       "      follow      favorite  \n",
       "0   0.000016  1.127469e-05  \n",
       "1   0.001516  7.742712e-05  \n",
       "2   0.000083  1.777745e-04  \n",
       "3   0.002219  3.379448e-05  \n",
       "4   0.000050  2.922827e-06  \n",
       "5   0.000005  9.888038e-07  \n",
       "6   0.000008  1.515313e-05  \n",
       "7   0.000095  1.165910e-04  \n",
       "8   0.000216  2.006952e-05  \n",
       "9   0.000067  1.080539e-03  \n",
       "10  0.000922  4.805734e-04  \n",
       "11  0.000043  8.183148e-04  \n",
       "12  0.000023  2.116532e-05  \n",
       "13  0.000091  8.347884e-05  \n",
       "14  0.000013  1.432022e-05  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8937a5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "     ... \n",
       "95    0.0\n",
       "96    0.0\n",
       "97    1.0\n",
       "98    0.0\n",
       "99    0.0\n",
       "Name: userid_bgm_song_id_12day_finish_rate, Length: 100, dtype: float16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['userid_bgm_song_id_12day_finish_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9785302",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.read_pickle(ROOT_PATH+'tmp/{}_feat_{}.pkl'.format(15,'_'.join(['userid','bgm_song_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f40a31d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userid_12day_like_sum 0\n",
      "userid_12day_like_mean 0\n",
      "userid_12day_click_avatar_sum 0\n",
      "userid_12day_click_avatar_mean 0\n",
      "userid_12day_forward_sum 0\n",
      "userid_12day_forward_mean 0\n",
      "userid_12day_comment_sum 0\n",
      "userid_12day_comment_mean 0\n",
      "userid_12day_follow_sum 0\n",
      "userid_12day_follow_mean 0\n",
      "userid_12day_favorite_sum 0\n",
      "userid_12day_favorite_mean 0\n",
      "feedid_12day_count 0\n",
      "feedid_12day_finish_rate 0\n",
      "feedid_12day_read_comment_sum 0\n",
      "feedid_12day_read_comment_mean 0\n",
      "feedid_12day_like_sum 0\n",
      "feedid_12day_like_mean 0\n",
      "feedid_12day_click_avatar_sum 0\n",
      "feedid_12day_click_avatar_mean 0\n",
      "feedid_12day_forward_sum 0\n",
      "feedid_12day_forward_mean 0\n",
      "feedid_12day_comment_sum 0\n",
      "feedid_12day_comment_mean 0\n",
      "feedid_12day_follow_sum 0\n",
      "feedid_12day_follow_mean 0\n",
      "feedid_12day_favorite_sum 0\n",
      "feedid_12day_favorite_mean 0\n",
      "authorid_12day_count 0\n",
      "authorid_12day_finish_rate 0\n",
      "authorid_12day_read_comment_sum 0\n",
      "authorid_12day_read_comment_mean 0\n",
      "authorid_12day_like_sum 0\n",
      "authorid_12day_like_mean 0\n",
      "authorid_12day_click_avatar_sum 0\n",
      "authorid_12day_click_avatar_mean 0\n",
      "authorid_12day_forward_sum 0\n",
      "authorid_12day_forward_mean 0\n",
      "authorid_12day_comment_sum 0\n",
      "authorid_12day_comment_mean 0\n",
      "authorid_12day_follow_sum 0\n",
      "authorid_12day_follow_mean 0\n",
      "authorid_12day_favorite_sum 0\n",
      "authorid_12day_favorite_mean 0\n",
      "userid_authorid_12day_count 0\n",
      "userid_authorid_12day_finish_rate 0\n",
      "userid_authorid_12day_read_comment_sum 0\n",
      "userid_authorid_12day_read_comment_mean 0\n",
      "userid_authorid_12day_like_sum 0\n",
      "userid_authorid_12day_like_mean 0\n",
      "userid_authorid_12day_click_avatar_sum 0\n",
      "userid_authorid_12day_click_avatar_mean 0\n",
      "userid_authorid_12day_forward_sum 0\n",
      "userid_authorid_12day_forward_mean 0\n",
      "userid_authorid_12day_comment_sum 0\n",
      "userid_authorid_12day_comment_mean 0\n",
      "userid_authorid_12day_follow_sum 0\n",
      "userid_authorid_12day_follow_mean 0\n",
      "userid_authorid_12day_favorite_sum 0\n",
      "userid_authorid_12day_favorite_mean 0\n",
      "userid_bgm_song_id_12day_count 0\n",
      "userid_bgm_song_id_12day_finish_rate 0\n",
      "userid_bgm_song_id_12day_read_comment_sum 0\n",
      "userid_bgm_song_id_12day_read_comment_mean 0\n",
      "userid_bgm_song_id_12day_like_sum 0\n",
      "userid_bgm_song_id_12day_like_mean 0\n",
      "userid_bgm_song_id_12day_click_avatar_sum 0\n",
      "userid_bgm_song_id_12day_click_avatar_mean 0\n",
      "userid_bgm_song_id_12day_forward_sum 0\n",
      "userid_bgm_song_id_12day_forward_mean 0\n",
      "userid_bgm_song_id_12day_comment_sum 0\n",
      "userid_bgm_song_id_12day_comment_mean 0\n",
      "userid_bgm_song_id_12day_follow_sum 0\n",
      "userid_bgm_song_id_12day_follow_mean 0\n",
      "userid_bgm_song_id_12day_favorite_sum 0\n",
      "userid_bgm_song_id_12day_favorite_mean 0\n",
      "userid_manual_keyword_id1_12day_count 0\n",
      "userid_manual_keyword_id1_12day_finish_rate 0\n",
      "userid_manual_keyword_id1_12day_read_comment_sum 0\n",
      "userid_manual_keyword_id1_12day_read_comment_mean 0\n",
      "userid_manual_keyword_id1_12day_like_sum 0\n",
      "userid_manual_keyword_id1_12day_like_mean 0\n",
      "userid_manual_keyword_id1_12day_click_avatar_sum 0\n",
      "userid_manual_keyword_id1_12day_click_avatar_mean 0\n",
      "userid_manual_keyword_id1_12day_forward_sum 0\n",
      "userid_manual_keyword_id1_12day_forward_mean 0\n",
      "userid_manual_keyword_id1_12day_comment_sum 0\n",
      "userid_manual_keyword_id1_12day_comment_mean 0\n",
      "userid_manual_keyword_id1_12day_follow_sum 0\n",
      "userid_manual_keyword_id1_12day_follow_mean 0\n",
      "userid_manual_keyword_id1_12day_favorite_sum 0\n",
      "userid_manual_keyword_id1_12day_favorite_mean 0\n"
     ]
    }
   ],
   "source": [
    "for f in feat:\n",
    "    print(f,a[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467d124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----开始推断1---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.05 Mb, 7.05 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:02<00:10,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.54 Mb, 3.54 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:05<00:10,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 Mb, 0.65 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:08<00:08,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397.81 Mb, 1397.81 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:53<00:30, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820.76 Mb, 820.76 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:21<00:18, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820.76 Mb, 820.76 Mb (0.00 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:47<00:00, 17.99s/it]\n",
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532.83 Mb, 940.79 Mb (38.62 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:07<00:00, 12.75it/s]\n",
      "  0%|          | 0/347 [00:00<?, ?it/s]/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 347/347 [01:09<00:00,  4.97it/s]\n",
      "100%|██████████| 347/347 [01:10<00:00,  4.94it/s]\n",
      "100%|██████████| 347/347 [01:29<00:00,  3.89it/s]\n",
      "100%|██████████| 347/347 [01:03<00:00,  5.49it/s]\n",
      "100%|██████████| 347/347 [00:59<00:00,  5.84it/s]\n",
      "100%|██████████| 347/347 [00:59<00:00,  5.84it/s]\n",
      "100%|██████████| 347/347 [00:40<00:00,  8.49it/s]\n",
      "100%|██████████| 347/347 [01:11<00:00,  4.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#----添加model到系统环境-----------\n",
    "import sys\n",
    "sys.path.append('./train/')\n",
    "#------加载模型1------------------\n",
    "from train.model.model1 import * # 转入模型\n",
    "##  处理数据---------------------------------------------\n",
    "ROOT_PATH='../data/'\n",
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']\n",
    "test_a=pd.read_csv('../data/wedata/wechat_algo_data2/test_a.csv')\n",
    "print('----开始推断1---------')\n",
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']\n",
    "test_a=pd.read_csv(ROOT_PATH+'wedata/wechat_algo_data2/test_a.csv')\n",
    "feed_info=pd.read_pickle(ROOT_PATH+'tmp/cat_feed_info.pkl')\n",
    "userid2nid=pickle.load(open(ROOT_PATH+'tmp/userid2nid.pkl','rb'))\n",
    "feedid2nid=pickle.load(open(ROOT_PATH+'tmp/feedid2nid.pkl','rb'))\n",
    "test_a=test_a.merge(feed_info[['feedid', 'authorid', 'videoplayseconds','manual_keyword_id1','manual_tag_id1']], on='feedid', how='left')\n",
    "test_a['date_']=15 # 由于 复赛数据B榜不可见 这里就不放入a榜数据使用\n",
    "max_day=15\n",
    "for stat_cols in tqdm([['userid'],['feedid'],['authorid'], ['userid', 'authorid'],['userid', 'manual_tag_id1'],\n",
    "        ['userid','manual_keyword_id1']]):\n",
    "    f = '_'.join(stat_cols)\n",
    "#     tmp.to_pickle('./tmp/{}_feat_{}.pkl'.format(target_day,'_'.join(stat_cols)))\n",
    "    tmp=pd.read_pickle(ROOT_PATH+'tmp/{}_feat_{}.pkl'.format(15,'_'.join(stat_cols)))\n",
    "    tmp=reduce_mem(tmp)\n",
    "    test_a = test_a.merge(tmp, on=stat_cols + ['date_'], how='left')\n",
    "    mean_tmp=pickle.load(open(ROOT_PATH+'tmp/{}_feat_mean.pkl'.format('_'.join(stat_cols)),'rb'))\n",
    "    for kk,vv in mean_tmp.items():\n",
    "        test_a[kk]=test_a[kk].fillna(vv) # 填充均值\n",
    "test_a=reduce_mem(test_a)\n",
    "gc.collect()\n",
    "# 加载特征list-------------------------\n",
    "feat=pickle.load(open(ROOT_PATH+'tmp/feat_list.pkl','rb'))\n",
    "#--------------归一化分布-----------\n",
    "normolizer_dict=pickle.load(open(ROOT_PATH+'tmp/normolizer_dict.pkl','rb'))\n",
    "for f in tqdm(feat):\n",
    "    tmp=test_a[f].values.astype('float16').clip(-1,1e8)\n",
    "    tmp_max=normolizer_dict[f+'_max'] # 这里 或许我得保留均值和方差\n",
    "    tmp_min=normolizer_dict[f+'_min']\n",
    "    test_a[f]=((tmp-tmp_min)/tmp_max).astype('float16')\n",
    "    \n",
    "src=torch.from_numpy(test_a['userid'].apply(lambda x: userid2nid[x]).values).long()\n",
    "dst=torch.from_numpy(test_a['feedid'].apply(lambda x: feedid2nid[x]).values).long()\n",
    "test_dense=torch.from_numpy(test_a[feat].values).float()\n",
    "# ------------trans-------------------------    \n",
    "hist_seq=torch.from_numpy(np.load(ROOT_PATH+'tmp/hist_list1.npy')).long()\n",
    "hist_id=torch.from_numpy((test_a['date_'].values-1)*len(userid2nid)).long()+src \n",
    "hist_seq2=torch.from_numpy(np.load(ROOT_PATH+'tmp/hist_list1.npy')).long()\n",
    "#-----------------trans1-------------------------------------------\n",
    "from train.model.trans1 import * # 转入模型\n",
    "model = torch.load(ROOT_PATH+'model/trans.pth')\n",
    "test_pred=test_pred_func(model,test_a,src,dst,hist_id,hist_seq,batch_size=4096*3)\n",
    "test_a[PREDICT_LIST]=test_pred\n",
    "subt1=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "#---------------trains1-hist2----------------------\n",
    "model = torch.load(ROOT_PATH+'model/trans1_hist2.pth')\n",
    "test_pred=test_pred_func(model,test_a,src,dst,hist_id,hist_seq2,batch_size=4096*3)\n",
    "test_a[PREDICT_LIST]=test_pred\n",
    "subt3=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "#-------------------reansv2-----------\n",
    "from train.model.trans1 import * # 转入模型\n",
    "model = torch.load(ROOT_PATH+'model/transv2.pth')\n",
    "test_pred=test_pred_func(model,test_a,src,dst,hist_id,hist_seq,batch_size=4096*3)\n",
    "test_a[PREDICT_LIST]=test_pred\n",
    "subt2=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "#----------modelv4----------------------------\n",
    "from train.model.model4 import *\n",
    "model = torch.load(ROOT_PATH+'model/model4.pth')\n",
    "test_pred=test_pred_func(model,test_a,src,dst,batch_size=4096*3)\n",
    "test_a[PREDICT_LIST]=test_pred\n",
    "sub4=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "\n",
    "#-----------------------------------------\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from train.model.model1 import * # 转入模型\n",
    "model = torch.load(ROOT_PATH+'model/model1.pth')\n",
    "#----------------inference-------------------------------------------------\n",
    "test_pred=test_pred_func(model,test_a,src,dst,test_dense,batch_size=4096*3)\n",
    "for i,f in enumerate(PREDICT_LIST):\n",
    "    test_a[f]=test_pred[:,i]\n",
    "sub1=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "#---\n",
    "model = torch.load(ROOT_PATH+'model/model1-1.pth')\n",
    "test_pred=test_pred_func(model,test_a,src,dst,test_dense,batch_size=4096*3)\n",
    "for i,f in enumerate(PREDICT_LIST):\n",
    "    test_a[f]=test_pred[:,i]\n",
    "sub1_1=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "\n",
    "\n",
    " #------加载模型2------------------\n",
    "from train.model.model2 import * # 转入模型\n",
    "model = torch.load(ROOT_PATH+'model/model2.pth')\n",
    "#----------------inference-------------------------------------------------\n",
    "test_pred=test_pred_func(model,test_a,src,dst,test_dense,batch_size=4096*3)\n",
    "for i,f in enumerate(PREDICT_LIST):\n",
    "    test_a[f]=test_pred[:,i]\n",
    "sub2=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "\n",
    "##------加载模型3------------------\n",
    "from train.model.model3 import * # 转入模型\n",
    "model = torch.load(ROOT_PATH+'model/model3.pth')\n",
    "#----------------inference-------------------------------------------------\n",
    "test_pred=test_pred_func(model,test_a,src,dst,test_dense,batch_size=4096*3)\n",
    "for i,f in enumerate(PREDICT_LIST):\n",
    "    test_a[f]=test_pred[:,i]\n",
    "sub3=test_a[['userid','feedid']+PREDICT_LIST]\n",
    "#---------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dacc308f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64b88147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.587526789486115"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.concat([sub1[PREDICT_LIST],sub3[PREDICT_LIST]],axis=1).corr().values\n",
    "diff=0\n",
    "for i in range(7):\n",
    "    diff+=a[i,i+7]\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subt1,subt2:6.7649\n",
    "subt1,subt3:6.24\n",
    "subt1,sub1:6.245\n",
    "sub1,subt3:6.228\n",
    "sub1,sub3:6.587\n",
    "sub1,sub4:6.3889\n",
    "sub1,sub1_1:6.6173\n",
    "sub1,sub2:6.485\n",
    "sub1,subt2:6.2423\n",
    "subt1,sub4:6.4165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9962948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------融合---------------------\n",
    "sub=sub1.copy()\n",
    "sub[PREDICT_LIST]=subt1[PREDICT_LIST]*0.2+subt2[PREDICT_LIST]*0.2+subt3[PREDICT_LIST]*0.15+\\\n",
    "sub1[PREDICT_LIST]*0.2+sub2[PREDICT_LIST]*0.05+sub3[PREDICT_LIST]*0.05+sub4[PREDICT_LIST]*0.1+sub1_1[PREDICT_LIST]*0.05\n",
    "\n",
    "sub.to_csv(os.path.join(ROOT_PATH+'submission','result.csv'),index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7f2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tf1",
   "language": "python",
   "name": "conda_tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
