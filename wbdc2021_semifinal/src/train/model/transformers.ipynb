{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40d7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.initializers import TruncatedNormal\n",
    "from tensorflow.python.keras.layers import LSTM, Lambda, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a4c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"  Simplified version of Transformer  proposed in 《Attention is all you need》\n",
    "\n",
    "      Input shape\n",
    "        - a list of two 3D tensor with shape ``(batch_size, timesteps, input_dim)`` if ``supports_masking=True`` .\n",
    "        - a list of two 4 tensors, first two tensors with shape ``(batch_size, timesteps, input_dim)``,last two tensors with shape ``(batch_size, 1)`` if ``supports_masking=False`` .\n",
    "\n",
    "\n",
    "      Output shape\n",
    "        - 3D tensor with shape: ``(batch_size, 1, input_dim)``  if ``output_type='mean'`` or ``output_type='sum'`` , else  ``(batch_size, timesteps, input_dim)`` .\n",
    "\n",
    "\n",
    "      Arguments\n",
    "            - **att_embedding_size**: int.The embedding size in multi-head self-attention network.\n",
    "            - **head_num**: int.The head number in multi-head  self-attention network.\n",
    "            - **dropout_rate**: float between 0 and 1. Fraction of the units to drop.\n",
    "            - **use_positional_encoding**: bool. Whether or not use positional_encoding\n",
    "            - **use_res**: bool. Whether or not use standard residual connections before output.\n",
    "            - **use_feed_forward**: bool. Whether or not use pointwise feed foward network.\n",
    "            - **use_layer_norm**: bool. Whether or not use Layer Normalization.\n",
    "            - **blinding**: bool. Whether or not use blinding.\n",
    "            - **seed**: A Python integer to use as random seed.\n",
    "            - **supports_masking**:bool. Whether or not support masking.\n",
    "            - **attention_type**: str, Type of attention, the value must be one of { ``'scaled_dot_product'`` , ``'additive'`` }.\n",
    "            - **output_type**: ``'mean'`` , ``'sum'`` or `None`. Whether or not use average/sum pooling for output.\n",
    "\n",
    "      References\n",
    "            - [Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in Neural Information Processing Systems. 2017.](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, att_embedding_size=1, head_num=8, dropout_rate=0.0, use_positional_encoding=True, use_res=True,\n",
    "                 use_feed_forward=True, use_layer_norm=False, blinding=True, seed=1024, supports_masking=False,\n",
    "                 attention_type=\"scaled_dot_product\", output_type=\"mean\", **kwargs):\n",
    "        if head_num <= 0:\n",
    "            raise ValueError('head_num must be a int > 0')\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        self.att_embedding_size = att_embedding_size\n",
    "        self.head_num = head_num\n",
    "        self.num_units = att_embedding_size * head_num\n",
    "        self.use_res = use_res\n",
    "        self.use_feed_forward = use_feed_forward\n",
    "        self.seed = seed\n",
    "        self.use_positional_encoding = use_positional_encoding\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.blinding = blinding\n",
    "        self.attention_type = attention_type\n",
    "        self.output_type = output_type\n",
    "        \n",
    "        self.supports_masking = supports_masking\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embedding_size = int(input_shape[0][-1])\n",
    "        if self.num_units != embedding_size:\n",
    "            raise ValueError(\n",
    "                \"att_embedding_size * head_num must equal the last dimension size of inputs,got %d * %d != %d\" % (\n",
    "                    self.att_embedding_size, self.head_num, embedding_size))\n",
    "        self.seq_len_max = int(input_shape[0][-2])\n",
    "        self.W_Query = self.add_weight(name='query', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=tf.keras.initializers.TruncatedNormal(seed=self.seed))\n",
    "        self.W_key = self.add_weight(name='key', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                     dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.TruncatedNormal(seed=self.seed + 1))\n",
    "        self.W_Value = self.add_weight(name='value', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=tf.keras.initializers.TruncatedNormal(seed=self.seed + 2))\n",
    "        if self.attention_type == \"additive\":\n",
    "            self.b = self.add_weight('b', shape=[self.att_embedding_size], dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.glorot_uniform(seed=self.seed))\n",
    "            self.v = self.add_weight('v', shape=[self.att_embedding_size], dtype=tf.float32,\n",
    "                                     initializer=tf.keras.initializers.glorot_uniform(seed=self.seed))\n",
    "        # if self.use_res:\n",
    "        #     self.W_Res = self.add_weight(name='res', shape=[embedding_size, self.att_embedding_size * self.head_num], dtype=tf.float32,\n",
    "        #                                  initializer=tf.keras.initializers.TruncatedNormal(seed=self.seed))\n",
    "        if self.use_feed_forward:\n",
    "            self.fw1 = self.add_weight('fw1', shape=[self.num_units, 4 * self.num_units], dtype=tf.float32,\n",
    "                                       initializer=tf.keras.initializers.glorot_uniform(seed=self.seed))\n",
    "            self.fw2 = self.add_weight('fw2', shape=[4 * self.num_units, self.num_units], dtype=tf.float32,\n",
    "                                       initializer=tf.keras.initializers.glorot_uniform(seed=self.seed))\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(\n",
    "            self.dropout_rate, seed=self.seed)\n",
    "        self.ln = LayerNormalization()\n",
    "        if self.use_positional_encoding:\n",
    "            self.query_pe = PositionEncoding()\n",
    "            self.key_pe = PositionEncoding()\n",
    "        # Be sure to call this somewhere!\n",
    "        super(Transformer, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, inputs, mask=None, training=None, **kwargs):\n",
    "\n",
    "        if self.supports_masking:\n",
    "            queries, keys = inputs\n",
    "            query_masks, key_masks = mask\n",
    "            query_masks = tf.cast(query_masks, tf.float32)\n",
    "            key_masks = tf.cast(key_masks, tf.float32)\n",
    "        else:\n",
    "            queries, keys, query_masks, key_masks = inputs\n",
    "\n",
    "            query_masks = tf.sequence_mask(\n",
    "                query_masks, self.seq_len_max, dtype=tf.float32)\n",
    "            key_masks = tf.sequence_mask(\n",
    "                key_masks, self.seq_len_max, dtype=tf.float32)\n",
    "            query_masks = tf.squeeze(query_masks, axis=1)\n",
    "            key_masks = tf.squeeze(key_masks, axis=1)\n",
    "\n",
    "        if self.use_positional_encoding:\n",
    "            queries = self.query_pe(queries)\n",
    "            keys = self.key_pe(queries)\n",
    "\n",
    "        querys = tf.tensordot(queries, self.W_Query,\n",
    "                              axes=(-1, 0))  # None T_q D*head_num\n",
    "        keys = tf.tensordot(keys, self.W_key, axes=(-1, 0))\n",
    "        values = tf.tensordot(keys, self.W_Value, axes=(-1, 0))\n",
    "\n",
    "        # head_num*None T_q D\n",
    "        querys = tf.concat(tf.split(querys, self.head_num, axis=2), axis=0)\n",
    "        keys = tf.concat(tf.split(keys, self.head_num, axis=2), axis=0)\n",
    "        values = tf.concat(tf.split(values, self.head_num, axis=2), axis=0)\n",
    "\n",
    "        if self.attention_type == \"scaled_dot_product\":\n",
    "            # head_num*None T_q T_k\n",
    "            outputs = tf.matmul(querys, keys, transpose_b=True)\n",
    "\n",
    "            outputs = outputs / (keys.get_shape().as_list()[-1] ** 0.5)\n",
    "        elif self.attention_type == \"additive\":\n",
    "            querys_reshaped = tf.expand_dims(querys, axis=-2)\n",
    "            keys_reshaped = tf.expand_dims(keys, axis=-3)\n",
    "            outputs = tf.tanh(tf.nn.bias_add(querys_reshaped + keys_reshaped, self.b))\n",
    "            outputs = tf.squeeze(tf.tensordot(outputs, tf.expand_dims(self.v, axis=-1), axes=[-1, 0]), axis=-1)\n",
    "        else:\n",
    "            raise ValueError(\"attention_type must be scaled_dot_product or additive\")\n",
    "\n",
    "        key_masks = tf.tile(key_masks, [self.head_num, 1])\n",
    "\n",
    "        # (h*N, T_q, T_k)\n",
    "        key_masks = tf.tile(tf.expand_dims(key_masks, 1),\n",
    "                            [1, tf.shape(queries)[1], 1])\n",
    "\n",
    "        paddings = tf.ones_like(outputs) * (-2 ** 32 + 1)\n",
    "\n",
    "        # (h*N, T_q, T_k)\n",
    "\n",
    "        outputs = tf.where(tf.equal(key_masks, 1), outputs, paddings, )\n",
    "        if self.blinding:\n",
    "            try:\n",
    "                outputs = tf.matrix_set_diag(outputs, tf.ones_like(outputs)[\n",
    "                    :, :, 0] * (-2 ** 32 + 1))\n",
    "            except AttributeError:\n",
    "                outputs = tf.compat.v1.matrix_set_diag(outputs, tf.ones_like(outputs)[\n",
    "                    :, :, 0] * (-2 ** 32 + 1))\n",
    "\n",
    "        outputs -= reduce_max(outputs, axis=-1, keep_dims=True)\n",
    "        outputs = softmax(outputs)\n",
    "        query_masks = tf.tile(query_masks, [self.head_num, 1])  # (h*N, T_q)\n",
    "        # (h*N, T_q, T_k)\n",
    "        query_masks = tf.tile(tf.expand_dims(\n",
    "            query_masks, -1), [1, 1, tf.shape(keys)[1]])\n",
    "\n",
    "        outputs *= query_masks\n",
    "\n",
    "        outputs = self.dropout(outputs, training=training)\n",
    "        # Weighted sum\n",
    "        # ( h*N, T_q, C/h)\n",
    "        result = tf.matmul(outputs, values)\n",
    "        result = tf.concat(tf.split(result, self.head_num, axis=0), axis=2)\n",
    "\n",
    "        if self.use_res:\n",
    "            # tf.tensordot(queries, self.W_Res, axes=(-1, 0))\n",
    "            result += queries\n",
    "        if self.use_layer_norm:\n",
    "            result = self.ln(result)\n",
    "\n",
    "        if self.use_feed_forward:\n",
    "            fw1 = tf.nn.relu(tf.tensordot(result, self.fw1, axes=[-1, 0]))\n",
    "            fw1 = self.dropout(fw1, training=training)\n",
    "            fw2 = tf.tensordot(fw1, self.fw2, axes=[-1, 0])\n",
    "            if self.use_res:\n",
    "                result += fw2\n",
    "            if self.use_layer_norm:\n",
    "                result = self.ln(result)\n",
    "\n",
    "        if self.output_type == \"mean\":\n",
    "            return reduce_mean(result, axis=1, keep_dims=True)\n",
    "        elif self.output_type == \"sum\":\n",
    "            return reduce_sum(result, axis=1, keep_dims=True)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c969be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torchtext\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "from deepctr_torch.models.deepfm import FM,DNN\n",
    "from deepctr_torch.layers  import CIN,InteractingLayer,CrossNet,CrossNetMix,AttentionSequencePoolingLayer\n",
    "from deepctr_torch.models.basemodel import *\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import auc,roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8e237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=128*3, nhead=8)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
    "src = torch.rand(10, 32, 128*3)\n",
    "out = transformer_encoder(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3b603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='../../../data/'\n",
    "user_data=pickle.load(open(ROOT_PATH+'tmp/user_data.pkl','rb'))\n",
    "\n",
    "feed_data=pickle.load(open(ROOT_PATH+'tmp/feed_data.pkl','rb'))\n",
    "\n",
    "item_texts=pickle.load(open(ROOT_PATH+'tmp/item_texts.pkl','rb'))\n",
    "feed_emb=np.load(ROOT_PATH+'tmp/feed_emb.npy')\n",
    "userid2nid=pickle.load(open(ROOT_PATH+'tmp/userid2nid.pkl','rb'))\n",
    "feedid2nid=pickle.load(open(ROOT_PATH+'tmp/feedid2nid.pkl','rb'))\n",
    "graph_emb=np.concatenate([np.load(ROOT_PATH+'tmp/grap_allembedding32_sg2.npy'),np.load(ROOT_PATH+'tmp/grap_allembedding32_hs2.npy')],axis=1)\n",
    "ratings=pd.read_csv(ROOT_PATH+'wedata/wechat_algo_data2/user_action.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba9fd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def disable_grad(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad=False\n",
    "class BagOfWordsPretrained(nn.Module):\n",
    "    def __init__(self, field, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.att_emb=Attn(hidden_dims)\n",
    "        input_dims = field.vocab.vectors.shape[1]\n",
    "        self.emb = nn.Embedding(\n",
    "            len(field.vocab.itos), input_dims,\n",
    "            padding_idx=field.vocab.stoi[field.pad_token])\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(field.vocab.vectors).float())\n",
    "        self.emb.weight.requires_grad = False\n",
    "#         self.proj = nn.Linear(input_dims, hidden_dims)\n",
    "#         nn.init.xavier_uniform_(self.proj.weight)\n",
    "#         nn.init.constant_(self.proj.bias, 0)\n",
    "\n",
    "#         disable_grad(self.emb) # 词向量不可训练\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, max_length) LongTensor\n",
    "        length: (batch_size,) LongTensor\n",
    "        \"\"\"\n",
    "#         x = self.emb(x).sum(1)# / length.unsqueeze(1).float() # 归一化\n",
    "        return  self.att_emb(self.emb(x))#self.proj(x)\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, field, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.att_emb=Attn(hidden_dims)\n",
    "        self.emb = nn.Embedding(\n",
    "            len(field.vocab.itos), hidden_dims,\n",
    "            padding_idx=field.vocab.stoi[field.pad_token])\n",
    "        nn.init.xavier_uniform_(self.emb.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.att_emb(self.emb(x))#.mean(1)#/ length.unsqueeze(1).float() # 归一化\n",
    "tokenize = lambda x: x.split(' ')\n",
    "fields = {}\n",
    "examples = []\n",
    "for key, texts in item_texts.items():\n",
    "    if  key in ['ocr','asr','description']:\n",
    "        fields[key] = torchtext.data.Field(include_lengths=True, lower=True,tokenize=tokenize, batch_first=True, fix_length=64)\n",
    "    else:\n",
    "        fields[key] = torchtext.data.Field(include_lengths=True, lower=True,tokenize=tokenize, batch_first=True, fix_length=5)\n",
    "    \n",
    "for i in range(len(feedid2nid)):\n",
    "    example = torchtext.data.Example.fromlist(\n",
    "        [item_texts[key][i] for key in item_texts.keys()],\n",
    "        [(key, fields[key]) for key in item_texts.keys()])  #( [feat1,feat2], [(key1,field1),(key2,field2)] )\n",
    "    examples.append(example)\n",
    "textset = torchtext.data.Dataset(examples, fields)\n",
    "for key, field in fields.items():\n",
    "    field.build_vocab(getattr(textset, key))\n",
    "for field_name, field in textset.fields.items():\n",
    "    examples = [getattr(textset[i], field_name) for i in range(len(feedid2nid))]\n",
    "\n",
    "    tokens, lengths = field.process(examples)\n",
    "\n",
    "    if not field.batch_first:\n",
    "        tokens = tokens.t()\n",
    "    # 给feed +上文本向量\n",
    "    feed_data[field_name] = tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0c0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transmodel(nn.Module):\n",
    "    def __init__(self,user_data,feed_data,textset,feed_embed,graph_emb,device):\n",
    "        super().__init__()\n",
    "        self.feed_data=feed_data\n",
    "        self.user_data=user_data\n",
    "        user_dict={'device':2,'userid':128}\n",
    "        feed_dict={'bgm_song_id':16, 'bgm_singer_id':16,'authorid':16,'dense':32,'hash_dense':32\n",
    "       ,'manual_keyword_id1':16,'manual_tag_id1':16,'machine_keyword_id1':16\n",
    "            ,'machine_tag_id1':16,'knn_feed':16,\n",
    "           'manual_tag_list':32,'manual_keyword_list':32,'machine_keyword_list':32,'asr':32,'description':32,'ocr':32\n",
    "                  }\n",
    "        self.model_dict=_init_input_modules(user_data,feed_data,textset, user_dict,feed_dict)\n",
    "        self.spare_liner=nn.Linear(8*16,128)\n",
    "        self.dense_liner=nn.Linear(32*2,128)\n",
    "        self.text_liner=nn.Linear(32*6+512+64,128)\n",
    "        self.feed_embed= nn.Parameter(torch.from_numpy(feed_embed).float(),requires_grad=False)\n",
    "        self.graph= nn.Parameter(torch.from_numpy(graph_emb).float(),requires_grad=False)\n",
    "        self.att_pool1=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool2=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool3=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "\n",
    "        self.mmoe=MMOELayer(sum(user_dict.values())+128*12, mmoe_hidden_dim=128,num_task=7,n_expert=5,expert_activation=None,device=device)\n",
    "        \n",
    "        self.liner1=nn.Linear(128,1)\n",
    "        self.liner2=nn.Linear(128,1)\n",
    "        self.liner3=nn.Linear(128,1)\n",
    "        self.liner4=nn.Linear(128,1)\n",
    "        self.liner5=nn.Linear(128,1)\n",
    "        self.liner6=nn.Linear(128,1)\n",
    "        self.liner7=nn.Linear(128,1)\n",
    "    def forward(self,userid,feedid,hist,mask_leng,is_train=True):\n",
    "        # hist=[B,T]  #T是padding的序列\n",
    "        # mask_leng=[B,1] # 每个batch中的长度\n",
    "        user_projections=[]\n",
    "        dense_embedding=[]\n",
    "        sparse_embedding=[]\n",
    "        text_embedding=[]\n",
    "        for feature, data in self.user_data.items():\n",
    "            module = self.model_dict[feature]\n",
    "            result = module(data)\n",
    "            user_projections.append(result)\n",
    "        for feature, data in self.feed_data.items():\n",
    "#             print(feature)\n",
    "            module = self.model_dict[feature]\n",
    "            result = module(data)\n",
    "            if result.shape[-1]==16:\n",
    "                sparse_embedding.append(result)\n",
    "            elif 'dense' in feature:\n",
    "                dense_embedding.append(result)\n",
    "            else:\n",
    "                text_embedding.append(result)\n",
    "        user_feat=torch.cat(user_projections,-1)\n",
    "        spare_emb=self.spare_liner(torch.cat(sparse_embedding,-1))\n",
    "        dense_emb=self.dense_liner(torch.cat(dense_embedding,-1))\n",
    "        text_emb=self.text_liner(torch.cat(text_embedding+[self.feed_embed,self.graph],-1))  \n",
    "        feed_feat=torch.cat([spare_emb,dense_emb,text_emb],-1) #128*3\n",
    "        \n",
    "        hist_feat=feed_feat[hist]\n",
    "        query=torch.unsqueeze(feed_feat[feedid],1)\n",
    "#         print(query,hist_feat.shape,mask_leng.shape)\n",
    "        \n",
    "        att_output1=self.att_pool1(query,hist_feat,mask_leng)\n",
    "        att_output1=att_output1.squeeze()\n",
    "        att_output2=self.att_pool2(query,hist_feat,mask_leng)\n",
    "        att_output2=att_output2.squeeze()\n",
    "        att_output3=self.att_pool3(query,hist_feat,mask_leng)\n",
    "        att_output3=att_output3.squeeze()\n",
    "        combine=torch.cat([user_feat[userid],feed_feat[feedid],att_output1,att_output2,att_output3],axis=-1)\n",
    "        outs=self.mmoe(combine)\n",
    "\n",
    "        logit_gnn1=self.liner1(outs[0])#+ffm1#128+1+128*2\n",
    "        logit_gnn2=self.liner2(outs[1])\n",
    "        \n",
    "        logit_gnn3=self.liner3(outs[2])\n",
    "        logit_gnn4=self.liner4(outs[3])\n",
    "        logit_gnn5=self.liner5(outs[4])\n",
    "        logit_gnn6=self.liner6(outs[5])\n",
    "        logit_gnn7=self.liner7(outs[6])\n",
    "\n",
    "        return logit_gnn1,logit_gnn2,logit_gnn3,logit_gnn4,logit_gnn5,logit_gnn6,logit_gnn7\n",
    "    \n",
    "def _init_input_modules(user_data,feed_data,textset, user_dict,feed_dict):\n",
    "    # We initialize the linear projections of each input feature ``x`` as\n",
    "    # follows:\n",
    "    # * If ``x`` is a scalar integral feature, we assume that ``x`` is a categorical\n",
    "    #   feature, and assume the range of ``x`` is 0..max(x).\n",
    "    # * If ``x`` is a float one-dimensional feature, we assume that ``x`` is a\n",
    "    #   numeric vector.\n",
    "    # * If ``x`` is a field of a textset, we process it as bag of words.\n",
    "    module_dict = nn.ModuleDict()\n",
    "    for column, data in user_data.items():\n",
    "#         if column in user_texts.keys():\n",
    "#             continue\n",
    "        if data.dtype == torch.float32: # 数值类型的特征\n",
    "            assert data.ndim == 2\n",
    "            m = nn.Linear(data.shape[1],user_dict[column]) # 数值特征 做个线性变换\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif data.dtype == torch.int64:\n",
    "            assert data.ndim == 1  # 整形的单值特征做个embedding\n",
    "            m = nn.Embedding(data.max() + 2, user_dict[column], padding_idx=-1)\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        module_dict[column] = m  # 不同的特征名字对应不同的处理moderl 这里或许可以加FM进去\n",
    "    \n",
    "    for column, data in feed_data.items():\n",
    "        if column in textset.fields.keys():\n",
    "            continue\n",
    "        if column =='manuual_tag_list_emb':\n",
    "            continue\n",
    "        if data.dtype == torch.float32: # 数值类型的特征\n",
    "            assert data.ndim == 2\n",
    "            m = nn.Linear(data.shape[1],feed_dict[column]) # 数值特征 做个线性变换\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif data.dtype == torch.int64:\n",
    "            assert data.ndim == 1  # 整形的单值特征做个embedding\n",
    "            m = nn.Embedding(data.max() + 2, feed_dict[column], padding_idx=-1)\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        module_dict[column] = m  # 不同的特征名字对应不同的处理moderl 这里或许可以加FM进去\n",
    "        \n",
    "    if textset is not None:\n",
    "        for column, field in textset.fields.items():\n",
    "            if field.vocab.vectors:\n",
    "                module_dict[column] = BagOfWordsPretrained(field,feed_dict[column])\n",
    "            else:\n",
    "                module_dict[column] = BagOfWords(field,feed_dict[column])\n",
    "    return module_dict\n",
    "\n",
    "class MMOELayer(nn.Module):\n",
    "    def __init__(self, hidden_size,device, mmoe_hidden_dim=128,num_task=4,n_expert=3,expert_activation=None,):\n",
    "        super(MMOELayer, self).__init__()\n",
    "         # experts\n",
    "        self.num_task=num_task\n",
    "        self.expert_activation = expert_activation\n",
    "        self.experts = torch.nn.Parameter(torch.rand(hidden_size, mmoe_hidden_dim, n_expert).to(device), requires_grad=True)\n",
    "        self.experts.data.normal_(0, 1)\n",
    "        self.experts_bias = torch.nn.Parameter(torch.rand(mmoe_hidden_dim, n_expert).to(device), requires_grad=True)\n",
    "        # gates\n",
    "        self.gates = [torch.nn.Parameter(torch.rand(hidden_size, n_expert), requires_grad=True).to(device) for _ in range(num_task)]\n",
    "        for gate in self.gates:\n",
    "            gate.data.normal_(0, 1)\n",
    "        self.gates_bias = [torch.nn.Parameter(torch.rand(n_expert), requires_grad=True).to(device) for _ in range(num_task)]\n",
    "        for i in range(num_task):\n",
    "            setattr(self, 'task_{}_dnn'.format(i+1),DNN(mmoe_hidden_dim,(128,128),dropout_rate=0.2,l2_reg=5e-5,use_bn=True))\n",
    "    def forward(self,x):\n",
    "         # mmoe\n",
    "        experts_out = torch.einsum('ij, jkl -> ikl', x, self.experts) # batch * mmoe_hidden_size * num_experts\n",
    "        experts_out += self.experts_bias\n",
    "        if self.expert_activation is not None:\n",
    "            experts_out = self.expert_activation(experts_out)\n",
    "        \n",
    "        gates_out = list()\n",
    "        for idx, gate in enumerate(self.gates):\n",
    "            gate_out = torch.einsum('ab, bc -> ac',x, gate) # batch * num_experts\n",
    "            if self.gates_bias:\n",
    "                gate_out += self.gates_bias[idx]\n",
    "            gate_out = nn.Softmax(dim=-1)(gate_out)\n",
    "            gates_out.append(gate_out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        outs = list()\n",
    "        for gate_output in gates_out:\n",
    "            expanded_gate_output = torch.unsqueeze(gate_output, 1) # batch * 1 * num_experts\n",
    "            weighted_expert_output = experts_out * expanded_gate_output.expand_as(experts_out) # batch * mmoe_hidden_size * num_experts\n",
    "            outs.append(torch.sum(weighted_expert_output, 2)) # batch * mmoe_hidden_size\n",
    "          # task tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_task):\n",
    "            oo = outs[i]\n",
    "            mod=getattr(self, 'task_{}_dnn'.format(i+1))\n",
    "            oo = mod(oo)\n",
    "            task_outputs.append(oo)\n",
    "        \n",
    "        return task_outputs\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, optimizer, k=5, alpha=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "\n",
    "    def update(self, group):\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "\n",
    "    def update_lookahead(self):\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self):\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {(id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "class WarmupLinearSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then linear decay.\n",
    "        Multiplies the learning rate defined in the optimizer by a dynamic variable determined by the current step.\n",
    "        Linearly increases the multiplicative variable from 0. to 1. over `warmup_steps` training steps.\n",
    "        Linearly decreases the multiplicative variable from 1. to 0. over remaining `t_total - warmup_steps` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.t_total = t_total\n",
    "        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1, self.warmup_steps))\n",
    "        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size,1)\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers*directions,B,H)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (T,B,H)\n",
    "        :param src_len:\n",
    "            used for masking. NoneType or tensor in shape (B) indicating sequence length\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''   \n",
    "        att=self.attn(x)\n",
    "        att=F.tanh(att)\n",
    "        att=F.softmax(att,1)\n",
    "        att_x=att*x\n",
    "        return att_x.sum(1)   \n",
    "class AdamW(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6, weight_decay=0.0, correct_bias=True):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n",
    "                        correct_bias=correct_bias)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "                state['step'] += 1\n",
    "                exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1.0 - beta2, grad, grad)\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                step_size = group['lr']\n",
    "                if group['correct_bias']:  # No bias correction for Bert\n",
    "                    bias_correction1 = 1.0 - beta1 ** state['step']\n",
    "                    bias_correction2 = 1.0 - beta2 ** state['step']\n",
    "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "                if group['weight_decay'] > 0.0:\n",
    "                    p.data.add_(-group['lr'] * group['weight_decay'], p.data)\n",
    "        return loss\n",
    "    \n",
    "def build_optimizer(model, train_steps, learning_rate):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False, eps=1e-8)\n",
    "    optimizer = Lookahead(optimizer, 5, 1)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=train_steps * 0.1, t_total=train_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def n_evaluate_nn(val_df,action_list,device,batch_size=512):\n",
    "    model.eval()\n",
    "    leng=len(val_df)\n",
    "    val_src=val_df['userid'].apply(lambda x:userid2nid[x]).values\n",
    "    val_dst=val_df['feedid'].apply(lambda x:feedid2nid[x]).values\n",
    "    val_hist_id=torch.from_numpy((val_df['date_'].values-1)*len(userid2nid)+val_src).long()\n",
    "    val_pred=[]\n",
    "    all_aucs=[]\n",
    "    weights=[0.30769231, 0.23076923, 0.15384615, 0.07692308, 0.07692308,0.07692308, 0.07692308]\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0,leng//batch_size+1)):\n",
    "            #         print(i*batch_size,(i+1)*batch_size)\n",
    "            batch_src=val_src[i*batch_size:(i+1)*batch_size]\n",
    "            batch_dst=val_dst[i*batch_size:(i+1)*batch_size]\n",
    "            batch_hist=hist_seq[val_hist_id[i*batch_size:(i+1)*batch_size]]\n",
    "            pred=model(batch_src,batch_dst,batch_hist[:,:-1],batch_hist[:,-1:].to(device))\n",
    "            val_pred.append(torch.cat(pred,axis=-1).sigmoid().cpu().numpy())\n",
    "        val_pred=np.concatenate(val_pred,axis=0)\n",
    "        for i,action in enumerate(action_list):\n",
    "            val_df['pred_'+action]=val_pred[:,i]\n",
    "            label_nunique = val_df.groupby(by='userid')[action].transform('nunique')\n",
    "            tmp_df = val_df[label_nunique == 2]\n",
    "            aucs = tmp_df.groupby(by='userid').apply(\n",
    "                lambda x: roc_auc_score(x[action].values, x['pred_'+action].values))\n",
    "            all_aucs.append(np.mean(aucs))\n",
    "            print('val %s uauc:'%action,np.mean(aucs))\n",
    "            print('val %s auc:'%action,roc_auc_score(val_df[action].values,val_pred[:,i]))\n",
    "        print('score uauc:',sum([all_aucs[i]*weights[i] for i in range(len(action_list))]))\n",
    "def evaluate_nn(val_df,action,batch_size=512):\n",
    "    model.eval()\n",
    "    leng=len(val_df)\n",
    "    val_src=val_df['userid'].apply(lambda x:userid2nid[x]).tolist()\n",
    "    val_dst=val_df['feedid'].apply(lambda x:feedid2nid[x]).tolist()\n",
    "    val_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0,leng//batch_size+1)):\n",
    "            #         print(i*batch_size,(i+1)*batch_size)\n",
    "            batch_src=val_src[i*batch_size:(i+1)*batch_size]\n",
    "            batch_dst=val_dst[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            pred=model(batch_src,batch_dst)\n",
    "\n",
    "            val_pred.append(pred.sigmoid().view(-1).cpu().numpy())\n",
    "        val_pred=np.concatenate(val_pred,axis=-1)\n",
    "        val_df['pred_'+action]=val_pred\n",
    "        label_nunique = val_df.groupby(by='userid')[action].transform('nunique')\n",
    "        tmp_df = val_df[label_nunique == 2]\n",
    "        \n",
    "        aucs = tmp_df.groupby(by='userid').apply(\n",
    "            lambda x: roc_auc_score(x[action].values, x['pred_'+action].values))\n",
    "        print('val uauc:',np.mean(aucs))\n",
    "        print('val auc:',roc_auc_score(val_df[action].values,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fc48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transmodelv2(nn.Module):\n",
    "    def __init__(self,user_data,feed_data,textset,feed_embed,graph_emb,device):\n",
    "        super().__init__()\n",
    "        self.feed_data=feed_data\n",
    "        self.user_data=user_data\n",
    "        user_dict={'device':2,'userid':128}\n",
    "        feed_dict={'bgm_song_id':16, 'bgm_singer_id':16,'authorid':16,'dense':32,'hash_dense':32\n",
    "       ,'manual_keyword_id1':16,'manual_tag_id1':16,'machine_keyword_id1':16\n",
    "            ,'machine_tag_id1':16,'knn_feed':16,\n",
    "           'manual_tag_list':32,'manual_keyword_list':32,'machine_keyword_list':32,'asr':32,'description':32,'ocr':32\n",
    "                  }\n",
    "        self.model_dict=_init_input_modules(user_data,feed_data,textset, user_dict,feed_dict)\n",
    "        self.spare_liner=nn.Linear(8*16,128)\n",
    "        self.dense_liner=nn.Linear(32*2,128)\n",
    "        self.text_liner=nn.Linear(32*6+512+64,128)\n",
    "        self.feed_embed= nn.Parameter(torch.from_numpy(feed_embed).float(),requires_grad=False)\n",
    "        self.graph= nn.Parameter(torch.from_numpy(graph_emb).float(),requires_grad=False)\n",
    "        self.att_pool1=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool2=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool3=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool4=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool5=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool6=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "        self.att_pool7=AttentionSequencePoolingLayer(att_hidden_units=(128,128),embedding_dim=128*3, weight_normalization=True,\n",
    "                                                supports_masking=False)\n",
    "\n",
    "        self.mmoe1=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        self.mmoe2=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        self.mmoe3=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        self.mmoe4=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        self.mmoe5=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        self.mmoe6=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        self.mmoe7=MMOELayer(sum(user_dict.values())+128*3, mmoe_hidden_dim=128,num_task=1,n_expert=5,expert_activation=None,device=device)\n",
    "        \n",
    "        self.liner1=nn.Linear(128,1)\n",
    "        self.liner2=nn.Linear(128,1)\n",
    "        self.liner3=nn.Linear(128,1)\n",
    "        self.liner4=nn.Linear(128,1)\n",
    "        self.liner5=nn.Linear(128,1)\n",
    "        self.liner6=nn.Linear(128,1)\n",
    "        self.liner7=nn.Linear(128,1)\n",
    "    def forward(self,userid,feedid,hist,mask_leng,is_train=True):\n",
    "        # hist=[B,T]  #T是padding的序列\n",
    "        # mask_leng=[B,1] # 每个batch中的长度\n",
    "        user_projections=[]\n",
    "        dense_embedding=[]\n",
    "        sparse_embedding=[]\n",
    "        text_embedding=[]\n",
    "        for feature, data in self.user_data.items():\n",
    "            module = self.model_dict[feature]\n",
    "            result = module(data)\n",
    "            user_projections.append(result)\n",
    "        for feature, data in self.feed_data.items():\n",
    "#             print(feature)\n",
    "            module = self.model_dict[feature]\n",
    "            result = module(data)\n",
    "            if result.shape[-1]==16:\n",
    "                sparse_embedding.append(result)\n",
    "            elif 'dense' in feature:\n",
    "                dense_embedding.append(result)\n",
    "            else:\n",
    "                text_embedding.append(result)\n",
    "        user_feat=torch.cat(user_projections,-1)\n",
    "        spare_emb=self.spare_liner(torch.cat(sparse_embedding,-1))\n",
    "        dense_emb=self.dense_liner(torch.cat(dense_embedding,-1))\n",
    "        text_emb=self.text_liner(torch.cat(text_embedding+[self.feed_embed,self.graph],-1))  \n",
    "        feed_feat=torch.cat([spare_emb,dense_emb,text_emb],-1) #128*3\n",
    "        \n",
    "        hist_feat=feed_feat[hist]\n",
    "        query=torch.unsqueeze(feed_feat[feedid],1)\n",
    "#        \n",
    "        att_output1=self.att_pool1(query,hist_feat,mask_leng)\n",
    "        att_output1=att_output1.squeeze()\n",
    "        att_output2=self.att_pool2(query,hist_feat,mask_leng)\n",
    "        att_output2=att_output2.squeeze()\n",
    "        att_output3=self.att_pool3(query,hist_feat,mask_leng)\n",
    "        att_output3=att_output3.squeeze()\n",
    "        att_output4=self.att_pool4(query,hist_feat,mask_leng)\n",
    "        att_output4=att_output4.squeeze()\n",
    "        att_output5=self.att_pool5(query,hist_feat,mask_leng)\n",
    "        att_output5=att_output5.squeeze()\n",
    "        att_output6=self.att_pool6(query,hist_feat,mask_leng)\n",
    "        att_output6=att_output6.squeeze()\n",
    "        att_output7=self.att_pool7(query,hist_feat,mask_leng)\n",
    "        att_output7=att_output7.squeeze()\n",
    "        \n",
    "        combine1=torch.cat([user_feat[userid],feed_feat[feedid],att_output1],axis=-1)\n",
    "        combine2=torch.cat([user_feat[userid],feed_feat[feedid],att_output2],axis=-1)\n",
    "        combine3=torch.cat([user_feat[userid],feed_feat[feedid],att_output3],axis=-1)\n",
    "        combine4=torch.cat([user_feat[userid],feed_feat[feedid],att_output4],axis=-1)\n",
    "        combine5=torch.cat([user_feat[userid],feed_feat[feedid],att_output5],axis=-1)\n",
    "        combine6=torch.cat([user_feat[userid],feed_feat[feedid],att_output6],axis=-1)\n",
    "        combine7=torch.cat([user_feat[userid],feed_feat[feedid],att_output7],axis=-1)\n",
    "        outs1=self.mmoe(combine1)\n",
    "        outs2=self.mmoe(combine2)\n",
    "        outs3=self.mmoe(combine3)\n",
    "        outs4=self.mmoe(combine4)\n",
    "        outs5=self.mmoe(combine5)\n",
    "        outs6=self.mmoe(combine6)\n",
    "        outs7=self.mmoe(combine7)\n",
    "\n",
    "        logit_gnn1=self.liner1(outs1)#+ffm1#128+1+128*2\n",
    "        logit_gnn2=self.liner2(outs2)\n",
    "        logit_gnn3=self.liner3(outs3)\n",
    "        logit_gnn4=self.liner4(outs4)\n",
    "        logit_gnn5=self.liner5(outs5)\n",
    "        logit_gnn6=self.liner6(outs6)\n",
    "        logit_gnn7=self.liner7(outs7)\n",
    "\n",
    "        return logit_gnn1,logit_gnn2,logit_gnn3,logit_gnn4,logit_gnn5,logit_gnn6,logit_gnn7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476cd720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICT_LIST=[\"read_comment\",\"like\", \"click_avatar\", \"forward\",'comment','follow','favorite']\n",
    "max_day=14\n",
    "train_ratings=ratings[(ratings.date_<max_day)]\n",
    "val_ratings=ratings[ratings.date_==max_day]\n",
    "del ratings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe952458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n"
     ]
    }
   ],
   "source": [
    "src=torch.from_numpy(train_ratings['userid'].apply(lambda x: userid2nid[x]).values).long()\n",
    "dst=torch.from_numpy(train_ratings['feedid'].apply(lambda x: feedid2nid[x]).values).long()\n",
    "hist_id=torch.from_numpy((train_ratings['date_'].values-1)*len(userid2nid)).long()+src\n",
    "labels=torch.from_numpy(train_ratings[PREDICT_LIST].values).float()\n",
    "hist_seq=torch.from_numpy(np.load(ROOT_PATH+'tmp/hist_list1.npy')).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68da1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3d7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myThread (threading.Thread):\n",
    "    def __init__(self, func, args):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.func=func\n",
    "        self.args= args\n",
    "    def run(self):\n",
    "        print('----start--------')\n",
    "        self.func(*self.args)\n",
    "        print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8f8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4096*2\n",
    "epochs=2\n",
    "def train1(Model,user_data,feed_data,textset,feed_emb,graph_emb,device):\n",
    "    for f,d in user_data.items():\n",
    "        user_data[f]=d.to(device)\n",
    "    for f,d in feed_data.items():\n",
    "        feed_data[f]=d.to(device)\n",
    "        \n",
    "    model = Model(user_data,feed_data,textset=textset\n",
    "                 ,feed_embed=feed_emb,graph_emb=graph_emb,device=device)\n",
    "    model=model.to(device)\n",
    "    train_steps = int(len(train_ratings) * epochs / batch_size) + 1\n",
    "    optimizer, scheduler = build_optimizer(model, train_steps, learning_rate=2e-2)\n",
    "    all_pred=[]\n",
    "\n",
    "    criti=nn.BCEWithLogitsLoss()\n",
    "    reg_criti=nn.MSELoss()\n",
    "    n_pos=len(train_ratings)\n",
    "    batch_index=np.arange(n_pos) # 生成正样本的index\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch: ----%d--'%epoch)\n",
    "        random.shuffle(batch_index) \n",
    "        epoch_loss=0\n",
    "        model.train()\n",
    "        for ind in tqdm(range(0,n_pos//batch_size+1)):\n",
    "            batch=batch_index[ind*batch_size:(ind+1)*batch_size]\n",
    "            batch_src=src[batch]\n",
    "            batch_dst=dst[batch]\n",
    "            batch_hist=hist_seq[hist_id[batch]]\n",
    "    #         print(batch_src)\n",
    "            logits =model(batch_src,batch_dst,batch_hist[:,:-1],batch_hist[:,-1:].to(device))\n",
    "            batch_label=labels[batch].to(device)\n",
    "            loss=criti(logits[0][:,0],batch_label[:,0])*0.8+criti(logits[1][:,0],batch_label[:,1])*0.8+\\\n",
    "            criti(logits[2][:,0],batch_label[:,2])*0.4+criti(logits[3][:,0],batch_label[:,3])*0.4+\\\n",
    "            criti(logits[4][:,0],batch_label[:,4])*0.3+criti(logits[5][:,0],batch_label[:,5])*0.3+criti(logits[6][:,0],batch_label[:,6])*0.3\n",
    "            epoch_loss+=loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if ind%1000==0:\n",
    "                print('binary loss:',loss.item())\n",
    "                batch_label=batch_label.cpu().numpy()\n",
    "                pred=torch.cat(logits,axis=-1).sigmoid().detach().cpu().numpy()\n",
    "    #             pred=logits.sigmoid().detach().cpu().numpy()\n",
    "                for ii,aa in enumerate(PREDICT_LIST):\n",
    "                    try:\n",
    "                        print('train %s auc:'%aa,roc_auc_score(batch_label[:,ii],pred[:,ii]))\n",
    "                    except:\n",
    "                        continue\n",
    "        print('epoch %d  loss: %f '%(epoch,epoch_loss/(len(batch_index)//batch_size+1)))\n",
    "        n_evaluate_nn(val_df=val_ratings,action_list=PREDICT_LIST,batch_size=2048,device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4962addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start--------\n",
      "----start--------\n",
      "epoch: ----0--\n",
      "epoch: ----0--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8188 [00:00<?, ?it/s]\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tione/notebook/envs/tf1/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-9-a3a1f21677ed>\", line 8, in run\n",
      "    self.func(*self.args)\n",
      "  File \"<ipython-input-10-b49b27e49325>\", line 31, in train1\n",
      "    logits =model(batch_src,batch_dst,batch_hist[:,:-1],batch_hist[:,-1:].to(device))\n",
      "  File \"/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-5-8e12b449b36c>\", line 57, in forward\n",
      "    result = module(data)\n",
      "  File \"/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/modules/sparse.py\", line 126, in forward\n",
      "    self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "  File \"/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py\", line 1852, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: Input, output and indices must be on the current device\n",
      "\n",
      "  0%|          | 0/8188 [00:00<?, ?it/s]/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/ipykernel/__main__.py:314: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  0%|          | 1/8188 [00:00<1:59:40,  1.14it/s]/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 2.429819107055664\n",
      "train read_comment auc: 0.518138553952238\n",
      "train like auc: 0.49945733594732783\n",
      "train click_avatar auc: 0.4394251816443968\n",
      "train forward auc: 0.6503630563933104\n",
      "train follow auc: 0.3678553981436248\n",
      "train favorite auc: 0.42283672811725614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1001/8188 [09:32<1:09:20,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.18441987037658691\n",
      "train read_comment auc: 0.9183549422916294\n",
      "train like auc: 0.849339492224249\n",
      "train click_avatar auc: 0.7992943584100765\n",
      "train forward auc: 0.8480566454144188\n",
      "train comment auc: 0.7920605838524489\n",
      "train follow auc: 0.7557553015097304\n",
      "train favorite auc: 0.8992325097847358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 24%|██▍       | 2001/8188 [19:02<59:43,  1.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.17367444932460785\n",
      "train read_comment auc: 0.9249567623099635\n",
      "train like auc: 0.863652145899703\n",
      "train click_avatar auc: 0.8201610701610702\n",
      "train forward auc: 0.9231487503783318\n",
      "train comment auc: 0.5955294979846097\n",
      "train follow auc: 0.8225832722534409\n",
      "train favorite auc: 0.8548913517758966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 37%|███▋      | 3001/8188 [28:34<50:08,  1.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.1758095622062683\n",
      "train read_comment auc: 0.9223037185601655\n",
      "train like auc: 0.87444414246321\n",
      "train click_avatar auc: 0.8335224029422602\n",
      "train forward auc: 0.9245605606737128\n",
      "train comment auc: 0.8711371686820569\n",
      "train follow auc: 0.917002688172043\n",
      "train favorite auc: 0.8941116544417277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 49%|████▉     | 4001/8188 [38:06<40:27,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.16956983506679535\n",
      "train read_comment auc: 0.9494719800312449\n",
      "train like auc: 0.8721608369640931\n",
      "train click_avatar auc: 0.8633813806414521\n",
      "train forward auc: 0.9154308125995833\n",
      "train comment auc: 0.6921480034192209\n",
      "train follow auc: 0.8957673545132291\n",
      "train favorite auc: 0.9229790876849701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 61%|██████    | 5001/8188 [47:38<30:48,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.16249528527259827\n",
      "train read_comment auc: 0.9412121438799718\n",
      "train like auc: 0.8769372083624204\n",
      "train click_avatar auc: 0.8927299920029528\n",
      "train forward auc: 0.9087614252341747\n",
      "train comment auc: 0.8753358573522227\n",
      "train follow auc: 0.8109875336103641\n",
      "train favorite auc: 0.9651918846247862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 73%|███████▎  | 6001/8188 [57:10<21:10,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.15573710203170776\n",
      "train read_comment auc: 0.9470169838105815\n",
      "train like auc: 0.8724221665762862\n",
      "train click_avatar auc: 0.8490058504938165\n",
      "train forward auc: 0.9032969552276563\n",
      "train comment auc: 0.9597427443318272\n",
      "train follow auc: 0.8803737176355643\n",
      "train favorite auc: 0.9583907845361724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 86%|████████▌ | 7001/8188 [1:06:39<11:27,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.15671928226947784\n",
      "train read_comment auc: 0.9502131987316095\n",
      "train like auc: 0.8670612648184433\n",
      "train click_avatar auc: 0.8856964256435481\n",
      "train forward auc: 0.9213729528918977\n",
      "train comment auc: 0.9883473799926713\n",
      "train follow auc: 0.9360938072554049\n",
      "train favorite auc: 0.9966489222445238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 98%|█████████▊| 8001/8188 [1:16:08<01:47,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary loss: 0.1740330010652542\n",
      "train read_comment auc: 0.9475752536410732\n",
      "train like auc: 0.8837377518989603\n",
      "train click_avatar auc: 0.8680706403684073\n",
      "train forward auc: 0.890609737527252\n",
      "train comment auc: 0.9256657708282433\n",
      "train follow auc: 0.7516395779868833\n",
      "train favorite auc: 0.8351509042033234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tione/notebook/envs/tf1/lib/python3.6/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 8188/8188 [1:17:54<00:00,  1.75it/s]\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tione/notebook/envs/tf1/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-9-a3a1f21677ed>\", line 8, in run\n",
      "    self.func(*self.args)\n",
      "  File \"<ipython-input-10-b49b27e49325>\", line 54, in train1\n",
      "    n_evaluate_nn(val_df=val_ratings,action_list=PREDICT_LIST,batch_size=2048,device=device)\n",
      "  File \"<ipython-input-4-ff5325d1bfba>\", line 340, in n_evaluate_nn\n",
      "    model.eval()\n",
      "NameError: name 'model' is not defined\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  loss: 0.178519 \n"
     ]
    }
   ],
   "source": [
    "p1=myThread (train1,(Transmodel,user_data,feed_data,textset,feed_emb,graph_emb,torch.device('cuda:0')))\n",
    "p1.start()\n",
    "p2=myThread (train1,(Transmodelv2,user_data,feed_data,textset,feed_emb,graph_emb,torch.device('cuda:2')))\n",
    "p2.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f,d in user_data.items():\n",
    "    user_data[f]=d.to(device)\n",
    "for f,d in feed_data.items():\n",
    "    feed_data[f]=d.to(device)\n",
    "\n",
    "model = Model(user_data,feed_data,textset=textset\n",
    "             ,feed_embed=feed_emb,graph_emb=graph_emb,device=device)\n",
    "model=model.to(device)\n",
    "train_steps = int(len(train_ratings) * epochs / batch_size) + 1\n",
    "optimizer, scheduler = build_optimizer(model, train_steps, learning_rate=2e-2)\n",
    "all_pred=[]\n",
    "\n",
    "criti=nn.BCEWithLogitsLoss()\n",
    "reg_criti=nn.MSELoss()\n",
    "n_pos=len(train_ratings)\n",
    "batch_index=np.arange(n_pos) # 生成正样本的index\n",
    "for epoch in range(epochs):\n",
    "    print('epoch: ----%d--'%epoch)\n",
    "    random.shuffle(batch_index) \n",
    "    epoch_loss=0\n",
    "    model.train()\n",
    "    for ind in tqdm(range(0,n_pos//batch_size+1)):\n",
    "        batch=batch_index[ind*batch_size:(ind+1)*batch_size]\n",
    "        batch_src=src[batch]\n",
    "        batch_dst=dst[batch]\n",
    "        batch_hist=hist_seq[hist_id[batch]]\n",
    "#         print(batch_src)\n",
    "        logits =model(batch_src,batch_dst,batch_hist[:,:-1],batch_hist[:,-1:].to(device))\n",
    "        batch_label=labels[batch].to(device)\n",
    "        loss=criti(logits[0][:,0],batch_label[:,0])*0.8+criti(logits[1][:,0],batch_label[:,1])*0.8+\\\n",
    "        criti(logits[2][:,0],batch_label[:,2])*0.4+criti(logits[3][:,0],batch_label[:,3])*0.4+\\\n",
    "        criti(logits[4][:,0],batch_label[:,4])*0.3+criti(logits[5][:,0],batch_label[:,5])*0.3+criti(logits[6][:,0],batch_label[:,6])*0.3\n",
    "        epoch_loss+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if ind%1000==0:\n",
    "            print('binary loss:',loss.item())\n",
    "            batch_label=batch_label.cpu().numpy()\n",
    "            pred=torch.cat(logits,axis=-1).sigmoid().detach().cpu().numpy()\n",
    "#             pred=logits.sigmoid().detach().cpu().numpy()\n",
    "            for ii,aa in enumerate(PREDICT_LIST):\n",
    "                try:\n",
    "                    print('train %s auc:'%aa,roc_auc_score(batch_label[:,ii],pred[:,ii]))\n",
    "                except:\n",
    "                    continue\n",
    "    print('epoch %d  loss: %f '%(epoch,epoch_loss/(len(batch_index)//batch_size+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff0010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tf1",
   "language": "python",
   "name": "conda_tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
